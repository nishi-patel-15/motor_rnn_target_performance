{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishi-patel-15/motor_rnn_target_performance/blob/main/Motor_RNNs_TargetPerformance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "7M333lN2dcyn"
      },
      "source": [
        "# Motor RNNs\n",
        "\n",
        "contact: steeve.laquitaine@epfl.ch\n",
        "\n",
        "Heavily inspired from [Feulner & Clopath, 2021](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008621)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1jVkqrLhdcyv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "TkMBKV2Rdcyw"
      },
      "outputs": [],
      "source": [
        "# import python packages\n",
        "import os\n",
        "import numpy as np\n",
        "import sklearn.linear_model as lm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "1npNrps5dcyy"
      },
      "outputs": [],
      "source": [
        "# @title Set the project path\n",
        "proj_path = \"proj_rnn/\"\n",
        "if not os.path.exists(proj_path):\n",
        "  os.makedirs(proj_path)\n",
        "\n",
        "# set the directories where the results will be saved\n",
        "savedir = os.path.join(proj_path, 'data/fig2/')\n",
        "if not os.path.exists(savedir):\n",
        "  os.makedirs(savedir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6jZ6mtMpdcyz"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "sOnXNE8vdcyz"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "Bw2ScNl5dcy0"
      },
      "outputs": [],
      "source": [
        "# @title RNN encoder\n",
        "class RNN(object):\n",
        "    \"\"\"\n",
        "    Class implementing a recurrent network (not following Dale's law).\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    * N: number of neurons\n",
        "    * N_in: how many inputs can the network have\n",
        "    * N_out: how many neurons are recorded by external device\n",
        "    * g: recurrent coupling strength\n",
        "    * p: connection probability\n",
        "    * tau: neuron time constant\n",
        "    * dt: set dt for simulation\n",
        "    * delta: defines initial learning rate for FORCE\n",
        "    * P_plastic: how many neurons are plastic in the recurrent network\n",
        "    \"\"\"\n",
        "    def __init__(self, N=800, g=1.5, p=0.1, tau=0.1, dt=0.01,\n",
        "                 N_in=6):\n",
        "        # set parameters\n",
        "        self.N = N\n",
        "        self.g = g\n",
        "        self.p = p\n",
        "        self.K = int(p*N)\n",
        "        self.tau = tau\n",
        "        self.dt = dt\n",
        "\n",
        "        # create recurrent W\n",
        "        mask = np.random.rand(self.N,self.N)<self.p\n",
        "        np.fill_diagonal(mask,np.zeros(self.N))\n",
        "        self.mask = mask\n",
        "        self.W = self.g / np.sqrt(self.K) * np.random.randn(self.N,self.N) * mask\n",
        "\n",
        "        # create Win and Wout\n",
        "        self._N_in = N_in\n",
        "        self.W_in = (np.random.rand(self.N, self._N_in)-0.5)*2.\n",
        "\n",
        "    @property\n",
        "    def N_in(self):\n",
        "        return self._N_in\n",
        "\n",
        "    @N_in.setter\n",
        "    def N_in(self, value):\n",
        "        self._N_in = value\n",
        "        self.W_in = (np.random.rand(self.N, self._N_in)-0.5)*2.\n",
        "\n",
        "    def save(self,filename):\n",
        "        np.savez(\n",
        "            filename,\n",
        "            N = self.N,\n",
        "            K = self.K,\n",
        "            tau = self.tau,\n",
        "            g = self.g,\n",
        "            p = self.p,\n",
        "            dt = self.dt,\n",
        "            W_in = self.W_in,\n",
        "            W = self.W,\n",
        "            N_in = self._N_in,\n",
        "        )\n",
        "\n",
        "    def load(self,filename):\n",
        "        net = np.load(filename+'.npz')\n",
        "        self.N = int(net['N'])\n",
        "        self.dt = float(net['dt'])\n",
        "        self.K = int(net['K'])\n",
        "        self.tau = float(net['tau'])\n",
        "        self.g = float(net['g'])\n",
        "        self.p = float(net['p'])\n",
        "        self.W_in = net['W_in']\n",
        "        self.W = net['W']\n",
        "        self._N_in = int(net['N_in'])\n",
        "\n",
        "    def update_activation(self):\n",
        "        self.z = np.tanh(self.r)\n",
        "\n",
        "    def update_neurons(self,ext):\n",
        "        self.r = self.r + self.dt/self.tau * \\\n",
        "             (-self.r + np.dot(self.W, self.z) + np.dot(self.W_in,ext))\n",
        "\n",
        "        self.update_activation()\n",
        "\n",
        "    def simulate(self, T, ext=None, r0=None):\n",
        "\n",
        "        # define time\n",
        "        time = np.arange(0,T,self.dt)\n",
        "        tsteps = int(T/self.dt)\n",
        "\n",
        "        # create input in case no input is given\n",
        "        if ext is None:\n",
        "            ext = np.zeros((tsteps,self.N_in))\n",
        "\n",
        "        # check if input has the right shape\n",
        "        if ext.shape[0]!=tsteps or ext.shape[1]!=self.N_in:\n",
        "            print('ERROR: stimulus shape should be (time x number of input nodes)')\n",
        "            return\n",
        "\n",
        "        # set initial condition\n",
        "        if r0 is None:\n",
        "            self.r = (np.random.rand(self.N)-0.5)*2.\n",
        "        else:\n",
        "            self.r = r0\n",
        "        self.update_activation()\n",
        "\n",
        "        # start simulation\n",
        "        record_r = np.zeros((tsteps,self.N))\n",
        "        record_r[0,:] = self.r\n",
        "        for i in range(1,tsteps):\n",
        "            self.update_neurons(ext=ext[i])\n",
        "            # store activity\n",
        "            record_r[i,:] = self.r\n",
        "        return time, record_r, np.tanh(record_r)\n",
        "\n",
        "    def relearn(self, trials, ext, ntstart, decoder, feedback, target, delta=1.,\n",
        "                wplastic=None):\n",
        "        \"\"\"\n",
        "        Args\n",
        "          self.z: RNN network's activation\n",
        "          ext (np.array): stimuli (n_targets, n timesteps, n_targets)\n",
        "          decoder (np.array): (N units, 2d coordinates) decoder weights\n",
        "          feedback (np.array): (N units, 2d coordinates) feedback weights\n",
        "          target: (n_targets, N timesteps, 2d coordinates) target coordinates\n",
        "\n",
        "        Returns:\n",
        "\n",
        "          loss (np.array): loss by trial\n",
        "        \"\"\"\n",
        "        # get number of timesteps within trial\n",
        "        tsteps = ext.shape[1]\n",
        "\n",
        "        # set up learning\n",
        "        if wplastic is None:\n",
        "            self.W_plastic = [np.where(self.W[i,:]!=0)[0] for i in range(self.N)]   #Any non-zero recurrent connection is plastic.\n",
        "        else:\n",
        "            self.W_plastic = wplastic                                           #????\n",
        "        self.P = [1./delta*np.eye(len(self.W_plastic[i])) for i in range(len(self.W_plastic))] #Each neuron gets a P matrix, which is the inverse correlation matrix used in Recursive Least Squares (RLS) learning. It controls how the weights are updated.\n",
        "\n",
        "        # create n trials of target indices chosen from lenth of total stimuli options\n",
        "        order = np.random.choice(range(ext.shape[0]), trials, replace=True)\n",
        "\n",
        "        # initialize calculated loss per trial\n",
        "        record_loss = np.zeros(trials)\n",
        "\n",
        "        # loop over trials\n",
        "        for t in range(trials):\n",
        "\n",
        "            # initialize loss\n",
        "            loss = 0.\n",
        "            self.r = (np.random.rand(self.N)-0.5)*2.                            # Random initial activation\n",
        "            self.update_activation()\n",
        "\n",
        "            # loop over time\n",
        "            for i in range(1,tsteps):\n",
        "\n",
        "                # update units\n",
        "                self.update_neurons(ext=ext[order[t],i])\n",
        "\n",
        "                # learn\n",
        "                if i > ntstart and i%2==0:\n",
        "\n",
        "                    # decode network's predicted\n",
        "                    # target coordinates\n",
        "                    c = decoder @ self.z\n",
        "\n",
        "                    # calculate prediction error between\n",
        "                    # decoded and true target coordinates (2,)\n",
        "                    errc = c - target[order[t], i]\n",
        "\n",
        "                    # calculate the error update assigned to each weight\n",
        "                    err1 = feedback @ errc\n",
        "\n",
        "                    # calculate loss\n",
        "                    loss += np.mean(err1**2)\n",
        "\n",
        "                    # update plastic recurrent weights\n",
        "                    for j in range(self.N):\n",
        "                        z_plastic = self.z[self.W_plastic[j]]\n",
        "                        pz = np.dot(self.P[j], z_plastic)\n",
        "                        norm = (1. + np.dot(z_plastic.T,  pz))\n",
        "                        self.P[j] -= np.outer(pz, pz)/norm\n",
        "\n",
        "                        # use error-transformed feedbacks to update\n",
        "                        # plastic weights\n",
        "                        self.W[j, self.W_plastic[j]] -= err1[j] * pz / norm\n",
        "\n",
        "            # tape loss\n",
        "            record_loss[t] = loss\n",
        "            print('Loss in Trial %d is %.5f'%(t+1,loss))\n",
        "        return record_loss\n",
        "\n",
        "    def calculate_manifold(self, trials, ext, ntstart):                         #ext = stimuli\n",
        "        tsteps = ext.shape[1]                                                   #tsteps = length of stimuli\n",
        "        T = self.dt*tsteps                                                      #T = real time\n",
        "        points = (tsteps-ntstart)\n",
        "        activity = np.zeros((points*trials,self.N))                             #store activity[timepoints,N]\n",
        "        order = np.random.choice(range(ext.shape[0]),trials,replace=True)       #chose a random trial\n",
        "        for t in range(trials):\n",
        "            time, r, z = self.simulate(T,ext[order[t]])                         #runs simulate on selected trial at all times\n",
        "            activity[t*points:(t+1)*points,:] = z[ntstart:,:]                   #stores in activity array (only after ntstart)\n",
        "        cov = np.cov(activity.T)                                                #Covariance of activity(N,trial time points)\n",
        "        ev,evec = np.linalg.eig(cov)                                            #eigenvalue and eigenvector from cov\n",
        "        pr = np.round(np.sum(ev.real)**2/np.sum(ev.real**2)).astype(int)        #Participation Ratio (PR): a measure of effective dimensionality of the manifold (See fig 3 of original paper)\n",
        "        xi = activity @ evec.real                                               #transformed activity profile into PCA space\n",
        "        return activity,cov,ev.real,evec.real,pr,xi,order\n",
        "\n",
        "def save_RNN(network, savedir:str):\n",
        "  \"\"\"write RNN object and weights in savedir\n",
        "  \"\"\"\n",
        "  network.save(savedir+'network')\n",
        "  np.save(savedir+'W_initial', network.W)\n",
        "\n",
        "def save_RNN_sinewave(network, savedir:str):\n",
        "  \"\"\"write RNN sinewave object and weights in savedir\n",
        "  \"\"\"\n",
        "  network.save(savedir + 'network_sinewave')\n",
        "  np.save(savedir + 'W_initial_sinewave', network.W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "_JwMuAhAdcy1"
      },
      "outputs": [],
      "source": [
        "# @title BCI decoders\n",
        "def train_reaching_decoder(inputP, target, order, n_output_units:int=2):        ###inputP = get manifold output[\"xi2\"][:, :, :reduced_dim #Target is get reaching targets output # Order is from manifold output as well # last is obvious idiot\n",
        "    \"\"\"train the decoder to perform the six-cue\n",
        "    motor reaching task\n",
        "    \"\"\"\n",
        "    # initialize predictor neural activity\n",
        "    X = np.zeros((inputP.shape[0]*inputP.shape[1], inputP.shape[-1]))           #X: Flattened neural data, shape = (total_timepoints, n_neurons)\n",
        "\n",
        "    # initialize predicted target\n",
        "    Y = np.zeros((inputP.shape[0]*inputP.shape[1], n_output_units))             #Y: Flattened target output, shape = (total_timepoints, n_output_units)\n",
        "\n",
        "    # fill up (This effectively flattens the trial-based data into one long array suitable for regression)\n",
        "    for j in range(inputP.shape[0]):\n",
        "        X[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = inputP[j]                #Fills in data from manifold\n",
        "        Y[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = target[order[j]]         #Fills in data from target task\n",
        "\n",
        "    # regress target against neural activity\n",
        "    reg = lm.LinearRegression()\n",
        "    reg.fit(X,Y)                                                                #Trains a linear model: Y ≈ X * coef + bias\n",
        "\n",
        "    # make predictions\n",
        "    y = reg.predict(X)\n",
        "    mse = np.mean((y-Y)**2)\n",
        "    return reg.coef_, mse                                                       #reg.coef_: The weight matrix (shape = (n_output_units, n_neurons)), representing how each neuron's activity contributes to each output dimension. mse is performance\n",
        "\n",
        "def create_reaching_task_decoder(reaching_network, n_output_units:int=2, target_max:float=0.2):\n",
        "  \"\"\"create feedforward decoder from RNN to (x,y) output units\n",
        "  for learning (random weights)\"\"\"                                              #By 'create' really just makes a matrix suitable for learning the proper weights.\n",
        "\n",
        "  # set parameters\n",
        "  SCALE = 0.04\n",
        "  DENOM = 0.2\n",
        "\n",
        "  # create random weights\n",
        "  reaching_decoder = np.random.randn(n_output_units, reaching_network.N)        #Creates a random weight matrix of shape (2, N) where N is the number of neurons.\n",
        "\n",
        "  initial_decoder_fac = SCALE * (target_max / DENOM)                            #Target max defined in parameters; max x,y distance of target\n",
        "\n",
        "  # normalize decoder matrix\n",
        "  reaching_decoder *= (initial_decoder_fac / np.linalg.norm(reaching_decoder))  #Scales the entire decoder matrix so that its norm matches initial_decoder_fac. Ensures that the initial decoder produces outputs of a reasonable magnitude (neither too small nor too large) — useful for stable learning.\n",
        "  return reaching_decoder                                                       #This computes the Frobenius norm (Euclidean norm for a matrix), which is: look it up, Upshot it its the magnitude of the full RNN matrix\n",
        "                                                                                #reaching_decoder *=  scalar. This scales every element in the reaching_decoder matrix by that scalar. The operation is in-place because of the *= operator, meaning it modifies the matrix directly rather than returning a new one.\n",
        "\n",
        "def train_force_exertion_decoder(inputP, target, order, n_output:int=1):        #Similar in structure to train_reaching_decoder. Unused in base data.\n",
        "    \"\"\"train the decoder to perform the force exertion\n",
        "    motor task. The network must apply force at\n",
        "    oscillating amplitude (following a sinewave function\n",
        "    of time)\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize predictor neural activity\n",
        "    X = np.zeros((inputP.shape[0]*inputP.shape[1], inputP.shape[-1]))\n",
        "\n",
        "    # initialize predicted target\n",
        "    Y = np.zeros((inputP.shape[0]*inputP.shape[1], n_output))\n",
        "\n",
        "    # fill up\n",
        "    for j in range(inputP.shape[0]):\n",
        "        X[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = inputP[j]\n",
        "        Y[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = target[order[j]]\n",
        "\n",
        "    # regress target against neural activity\n",
        "    reg = lm.LinearRegression()\n",
        "    reg.fit(X, Y)\n",
        "\n",
        "    # make predictions\n",
        "    y = reg.predict(X)\n",
        "    mse = np.mean((y-Y)**2)\n",
        "    return reg.coef_, mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "zRTY0RFqdcy2"
      },
      "outputs": [],
      "source": [
        "# @title Feedback weights\n",
        "def get_feedback_weights(decoder):                                              #Still not sure exactly what is going on. Isn't input essentially blank here?\n",
        "  \"\"\"calculate feedback weights from (x,y) output units back to RNN\n",
        "  as the matrix inverse of the feedforward decoder weights from the RNN to\n",
        "  the output units\"\"\"\n",
        "  return np.linalg.pinv(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "oeVfbgXfdcy2"
      },
      "outputs": [],
      "source": [
        "# @title Loss function\n",
        "def get_cost(result, target, order):                                            #Part of transform_reaching. Calculates the mean squared difference between the end results and the target\n",
        "  cost = 0\n",
        "  for j in range(result.shape[0]):\n",
        "    error = result[j, :, :] - target[order[j], :, :]\n",
        "    cost += np.mean(error**2)\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PLot Loss\n",
        "def plot_loss_over_trials(losses):\n",
        "    trials = len(losses)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(range(1, trials + 1), losses, marker='o', linestyle='-')\n",
        "    plt.xlabel(\"Trial\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss per Trial\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "B-39etsCtGMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "6GFzFSi6dcy3"
      },
      "outputs": [],
      "source": [
        "# @title Get the manifold\n",
        "def get_manifold(network):\n",
        "\n",
        "  # calculate the manifold\n",
        "  activity, cov, ev, evec, pr, xi, order = network.calculate_manifold(trials=manifold_trials, ext=stimulus, ntstart=pulse_length)\n",
        "\n",
        "  # reshape the activity\n",
        "  activity_reshaped = activity.reshape(manifold_trials, -1, network.N)\n",
        "  xi2 = xi.reshape(manifold_trials, -1, network.N)\n",
        "  return {\"xi2\":xi2, \"order\":order, \"xi\":xi, \"cov\":cov, \"ev\":ev, \"evec\":evec, \"pr\":pr,\"activity\":activity, \"activity_reshaped\":activity_reshaped}\n",
        "\n",
        "def save_reaching_manifold(data, T):\n",
        "  dic = {'manifold': {'original': data['manifold']}, 'perturbations': {'transformed':T}}\n",
        "  np.save(savedir + 'reaching_relearning_results', dic)\n",
        "\n",
        "def transform_reaching(reaching_network, manifold_out, W_bci4, n_output_units:int=2):\n",
        "\n",
        "  P = manifold_out[\"evec\"].real.T\n",
        "  D = np.zeros((2, reaching_network.N))\n",
        "  D[:,:reduced_dim] = W_bci4\n",
        "  transformed = D @ P\n",
        "  result = manifold_out[\"activity_reshaped\"] @ transformed.T\n",
        "  cost = get_cost(result, target[:,pulse_length:,:], manifold_out[\"order\"])\n",
        "  return transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "nenZCf61dcy3"
      },
      "outputs": [],
      "source": [
        "# @title simulation\n",
        "def simulate_reaching(savdir, dt):\n",
        "\n",
        "  # set plot parameters\n",
        "  COL_ORIG = 'k'\n",
        "  ALPHA = 1\n",
        "\n",
        "  # load velocity data\n",
        "  data = np.load(savdir + 'reaching_relearning_results.npy', allow_pickle=True).item()\n",
        "  activity = data['manifold']['original']['activity2']\n",
        "  o_original = activity @ data['perturbations']['transformed'].T\n",
        "\n",
        "  # reconstruct trajectories from velocities\n",
        "  pos_original = np.zeros(o_original.shape)\n",
        "  for j in range(activity.shape[1]):\n",
        "      pos_original[:,j,:] = pos_original[:,j-1,:] + o_original[:,j,:]*dt\n",
        "\n",
        "  # plot trajectories\n",
        "  plt.figure(figsize=(15,10), dpi=96)\n",
        "  plt.subplot(2,3,3)\n",
        "  for j in range(manifold_trials):\n",
        "      plt.plot(pos_original[j,:,0], pos_original[j,:,1], COL_ORIG, alpha=ALPHA);\n",
        "  plt.title('simulated reaching');\n",
        "  plt.xlabel('x-position on screen');\n",
        "  plt.ylabel('y-position on screen');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Ev5EBlU4dcy4"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "zrb4ZucRdcy4"
      },
      "outputs": [],
      "source": [
        "# @title \"reaching\" task\n",
        "def create_reaching_task_stimuli(tsteps:int, pulse_steps:int, n_targets:int=6, amplitude:float=1., twod:bool=False):\n",
        "    \"\"\"create the set of stimuli, which we sample from at each trial\n",
        "\n",
        "    Args:\n",
        "      tsteps (int):\n",
        "      pulse_steps (int):\n",
        "      n_targets (int):\n",
        "      amplitude (float):\n",
        "      twod (bool):\n",
        "\n",
        "    Returns:\n",
        "      (np.array): array of (n_targets, pulse_steps, n_targets) stimuli\n",
        "    \"\"\"\n",
        "\n",
        "    # create stimulus\n",
        "    stimulus = np.zeros((n_targets, tsteps, n_targets))\n",
        "    if twod:\n",
        "        phis = np.linspace(0,2*np.pi,targets,endpoint=False) + np.pi / 6\n",
        "        for j in range(stimulus.shape[0]):\n",
        "            stimulus[j,:pulse_length,0] = amplitude*np.cos(phis[j])\n",
        "            stimulus[j,:pulse_length,1] = amplitude*np.sin(phis[j])\n",
        "            stimulus[j,:pulse_length,2:] = 0\n",
        "    else:\n",
        "        for j in range(n_targets):\n",
        "            stimulus[j,:pulse_steps,j] = amplitude\n",
        "    return stimulus\n",
        "\n",
        "def create_reaching_task_targets(tsteps, pulse_steps, n_targets:int=6, stype='constant', target_max:float=0.2):\n",
        "    \"\"\"create the set of target coordinates (6 by default) that the network\n",
        "    must reach before the end of a trial. The network starts from the center of\n",
        "    the computer screen (coordinate: (0,0))\n",
        "    \"\"\"\n",
        "    # create target trajectories\n",
        "    phis = np.linspace(0, 2*np.pi, n_targets, endpoint=False) + np.pi / 6\n",
        "    rs = np.zeros(tsteps)\n",
        "\n",
        "    # define each target's x and y coordinate\n",
        "    rs[pulse_steps:] = np.ones(tsteps-pulse_steps)*target_max                   #Stimuli start at 0,0 then move to final position at 'pulse_steps'\n",
        "    traj = np.zeros((n_targets,tsteps,2))\n",
        "    for j in range(n_targets):\n",
        "\n",
        "        # create x-coordinate on screen\n",
        "        traj[j,:,0] = rs*np.cos(phis[j])\n",
        "\n",
        "        # create y-coordinate on screen\n",
        "        traj[j,:,1] = rs*np.sin(phis[j])\n",
        "    return traj\n",
        "\n",
        "def plot_reaching_task_stimuli(stimulus, n_targets:int, tsteps:int, T:int):\n",
        "\n",
        "  # plot target cue with \"pulse_steps\" duration\n",
        "  # at the beginning of each trial\n",
        "  stimulus_set = np.arange(0, n_targets,1)\n",
        "\n",
        "  fig, axes = plt.subplots(n_targets, 1, figsize=(30,9))\n",
        "\n",
        "  for target in stimulus_set:\n",
        "    axes[target].imshow(stimulus[target,:,:].T, aspect=10, cmap=\"binary\");\n",
        "\n",
        "    # legend\n",
        "    axes[target].set_yticks(stimulus_set)\n",
        "    axes[target].set_yticklabels(stimulus_set, fontsize=9)\n",
        "    axes[target].set_xticks([0, tsteps])\n",
        "    axes[target].set_xticklabels([0, T])\n",
        "    axes[target].set_ylabel(\"possible targets\", fontsize=9)\n",
        "\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "\n",
        "  fig.tight_layout()\n",
        "\n",
        "  print(\"stimuli:\")\n",
        "  print(f\"-a set of {stimulus.shape[0]} possible trial stimuli (panels)\")\n",
        "  print(f\"-{stimulus.shape[1]} timesteps within a trial stimulus\")\n",
        "  print(f\"-{stimulus.shape[2]} possible cued target in a trial stimulus\")\n",
        "\n",
        "def plot_reaching_task_targets(target, tsteps:int, T:int):\n",
        "\n",
        "  # count targets\n",
        "  n_targets = target.shape[0]\n",
        "\n",
        "  # plot target coordinates throughout trial\n",
        "  fig, axes = plt.subplots(n_targets,1, figsize=(6,6))\n",
        "  for target_i in tuple(range(n_targets)):\n",
        "    axes[target_i].plot(target[target_i,:,:])\n",
        "\n",
        "    # legend\n",
        "    axes[target_i].set_xticks([0, tsteps])\n",
        "    axes[target_i].set_xticklabels([0, T])\n",
        "    axes[target_i].set_ylabel(\"target\" \"\\n\" \"coord (a.u.)\", fontsize=9)\n",
        "    axes[target_i].set_ylim([target.min()-0.01, target.max()+0.01])\n",
        "    # axes[target_i].legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False)\n",
        "\n",
        "\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "  plt.legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False)\n",
        "\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "TTLiJW6Xdcy4"
      },
      "outputs": [],
      "source": [
        "# @title \"force\" task\n",
        "def create_force_task_stimuli(tsteps:int, pulse_steps:int, n_targets:int=1, amplitude:float=1., twod:bool=False):\n",
        "    \"\"\"create a stimulus set\n",
        "\n",
        "    Args:\n",
        "      tsteps (int):\n",
        "      pulse_steps (int):\n",
        "      n_targets (int):\n",
        "      amplitude (float)\n",
        "      twod (bool):\n",
        "\n",
        "    Returns:\n",
        "      (np.array): array of (n_targets, pulse_steps, n_targets) stimuli\n",
        "    \"\"\"\n",
        "\n",
        "    # create stimuli\n",
        "    stimulus = np.zeros((n_targets, tsteps, n_targets))\n",
        "    for j in range(n_targets):\n",
        "        stimulus[j,:pulse_steps,j] = amplitude\n",
        "    return stimulus\n",
        "\n",
        "def plot_force_stimuli(stimulus, n_targets:int, tsteps:int, T:int):\n",
        "\n",
        "  # plot target cue with \"pulse_steps\" duration\n",
        "  # at the beginning of each trial\n",
        "  stimulus_set = np.arange(0, n_targets, 1)\n",
        "  fig, axes = plt.subplots(n_targets, 1, figsize=(30,9))\n",
        "  for target in stimulus_set:\n",
        "\n",
        "    # plot\n",
        "    axes[target].imshow(stimulus[target,:,:].T, aspect=10, cmap=\"binary\");\n",
        "\n",
        "    # legend\n",
        "    axes[target].set_yticks(stimulus_set)\n",
        "    axes[target].set_yticklabels(stimulus_set, fontsize=9)\n",
        "    axes[target].set_xticks([0, tsteps])\n",
        "    axes[target].set_xticklabels([0, T])\n",
        "    axes[target].set_ylabel(\"possible targets\", fontsize=9)\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "  fig.tight_layout()\n",
        "  print(\"stimuli:\")\n",
        "  print(f\"-a set of {stimulus.shape[0]} possible trial stimuli (panels)\")\n",
        "  print(f\"-{stimulus.shape[1]} timesteps within a trial stimulus\")\n",
        "  print(f\"-{stimulus.shape[2]} possible cued target in a trial stimulus\")\n",
        "\n",
        "def create_force_task_targets(tsteps, pulse_steps, targets:list=[1, 10], target_max:float=0.2):\n",
        "  \"\"\"exert force with an oscillatorily increasing and decreasing amplitude\n",
        "  \"\"\"\n",
        "  n_targets = len(targets)\n",
        "  rs = np.zeros(tsteps)\n",
        "  traj = np.zeros((n_targets, tsteps, 1))\n",
        "  rs[pulse_steps:] = np.ones(tsteps - pulse_steps) * target_max\n",
        "  x_coord = np.linspace(-2*np.pi, 2*np.pi, tsteps, endpoint=False)\n",
        "  freq = []\n",
        "  for ix in range(n_targets):\n",
        "    traj[ix,:,0] = rs * np.sin(targets[ix] * x_coord)\n",
        "  return traj\n",
        "\n",
        "def plot_force_task_targets(target, tsteps:int, T:int):\n",
        "\n",
        "  # count targets\n",
        "  n_targets = target.shape[0]\n",
        "\n",
        "  # plot target coordinates throughout trial\n",
        "  fig, axes = plt.subplots(n_targets,1, figsize=(6,6));\n",
        "  for target_i in tuple(range(n_targets)):\n",
        "\n",
        "    # plot\n",
        "    axes[target_i].plot(target[target_i,:,:]);\n",
        "\n",
        "    # legend\n",
        "    axes[target_i].set_xticks([0, tsteps]);\n",
        "    axes[target_i].set_xticklabels([0, T]);\n",
        "    axes[target_i].set_ylabel(\"target\" \"\\n\" \"coord (a.u.)\", fontsize=9);\n",
        "    axes[target_i].set_ylim([target.min()-0.01, target.max()+0.01]);\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\");\n",
        "  plt.legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False);\n",
        "  fig.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NcQfmmJldcy5"
      },
      "source": [
        "## Create task 1: \"reaching\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "WltOVBJ5dcy5"
      },
      "outputs": [],
      "source": [
        "# @title set parameters\n",
        "# TODO: create dictionary\n",
        "\n",
        "seed_id = 2                 # random seed for this simulation\n",
        "np.random.seed(seed_id)\n",
        "\n",
        "# time parameters\n",
        "dt = 0.01                   # time discretization (secs, see paper table 1)\n",
        "T = 2                       # trial duration (secs, see paper table 1)\n",
        "time = np.arange(0, T, dt)\n",
        "tsteps = len(time)          # number of time steps within a trial\n",
        "pulse_length = int(0.2/dt)  # pulse length in number of timesteps\n",
        "\n",
        "# network parameters\n",
        "N = 800                     # RNN number of units\n",
        "g = 1.5                     # RNN recurrent connection strengths (a.u)\n",
        "p = 0.1                     # RNN connection probability\n",
        "tau = 0.1                   # unit time constant tau (secs)\n",
        "N_OUTPUT_UNITS = 2          # number of output units (2 for x and y)\n",
        "\n",
        "# task parameters\n",
        "targets = 8                 # number of reaching targets\n",
        "stimulus_type = 'constant'  # constant, linear, normal\n",
        "target_max = 5.0            # 0.2 or 0.01\n",
        "n_learning1_trials = 80       # initial network learning\n",
        "delta = 20.\n",
        "relearning_trials = 80     # relearning\n",
        "deltarec = 20.\n",
        "\n",
        "# analyses parameters\n",
        "manifold_trials = 100        # manifold calculation\n",
        "reduced_dim = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3BqbMmmSdcy5"
      },
      "outputs": [],
      "source": [
        "# @title Create stimuli and targets\n",
        "\n",
        "# create stimuli and plot\n",
        "stimulus = create_reaching_task_stimuli(tsteps, pulse_length, n_targets=targets, twod=False)\n",
        "plot_reaching_task_stimuli(stimulus, targets, tsteps, T)\n",
        "\n",
        "# create target (targets x timesteps x 2D coordinates) and plot\n",
        "target = create_reaching_task_targets(\n",
        "    tsteps,\n",
        "    pulse_length,\n",
        "    n_targets=targets,\n",
        "    stype=stimulus_type,\n",
        "    target_max=target_max\n",
        "    )\n",
        "plot_reaching_task_targets(target, tsteps, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "574307IZdcy6"
      },
      "outputs": [],
      "source": [
        "# @title build and train the network\n",
        "# create and save RNN encoder\n",
        "reaching_network = RNN(N=N, g=g, p=p, tau=tau, dt=dt, N_in=targets)\n",
        "save_RNN(reaching_network, savedir)\n",
        "\n",
        "# create feedforward decoder from RNN to (x,y) output units\n",
        "reaching_decoder = create_reaching_task_decoder(reaching_network,\n",
        "                                                n_output_units=N_OUTPUT_UNITS)\n",
        "\n",
        "# create feedback weights from (x,y) output units back to RNN\n",
        "reaching_feedback = get_feedback_weights(reaching_decoder)\n",
        "\n",
        "# train and save the RNN encoder weights (learn the task)\n",
        "reaching_loss = reaching_network.relearn(n_learning1_trials, stimulus,\n",
        "                                         pulse_length, reaching_decoder,\n",
        "                                         reaching_feedback, target, delta=delta)\n",
        "plot_loss_over_trials(reaching_loss)\n",
        "np.save(f'{savedir}W_stabilized_reaching', reaching_network.W)\n",
        "w1_reaching = reaching_network.W.copy()\n",
        "\n",
        "# get the RNN's manifold\n",
        "manifold_out = get_manifold(reaching_network)\n",
        "\n",
        "# train the decoder\n",
        "W_bci4, l4 = train_reaching_decoder(manifold_out[\"xi2\"][:, :, :reduced_dim],\n",
        "                                    target[:, pulse_length:, :],\n",
        "                                    manifold_out[\"order\"],\n",
        "                                    n_output_units=N_OUTPUT_UNITS)\n",
        "\n",
        "# transform\n",
        "transformed = transform_reaching(reaching_network, manifold_out,\n",
        "                                 W_bci4, n_output_units=N_OUTPUT_UNITS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "KHhq6r3Vdcy7"
      },
      "outputs": [],
      "source": [
        "# @title Save run data\n",
        "# format and save data for this run\n",
        "run_data = {\n",
        "    'params':{\n",
        "        'dt':dt,\n",
        "        'T':T,\n",
        "        'time':time,\n",
        "        'tsteps':tsteps,\n",
        "        'pulse_length':pulse_length,\n",
        "        'manifold_trials':manifold_trials,\n",
        "        'target_max':target_max,\n",
        "        'stimulus_type':stimulus_type,\n",
        "        'N':N,\n",
        "        'tau':tau,\n",
        "        'g':g,\n",
        "        'p':p\n",
        "        },\n",
        "    'stimulus':stimulus,\n",
        "    'target':target,\n",
        "    'stabilizing':{\n",
        "        'learning_trials':n_learning1_trials,\n",
        "        'delta':delta,\n",
        "        'decoder':reaching_decoder,\n",
        "        'feedback':reaching_feedback,\n",
        "        'stabilize_loss':reaching_loss\n",
        "        },\n",
        "    'manifold':{\n",
        "        'activity':manifold_out[\"activity\"],\n",
        "        'activity2':manifold_out[\"activity_reshaped\"],\n",
        "        'xi':manifold_out[\"xi\"],\n",
        "        'xi2':manifold_out[\"xi2\"],\n",
        "        'cov':manifold_out[\"cov\"],\n",
        "        'ev':manifold_out[\"ev\"],\n",
        "        'evec':manifold_out[\"evec\"],\n",
        "        'pr':manifold_out[\"pr\"],\n",
        "        'order': manifold_out[\"order\"]\n",
        "        },\n",
        "    'decoding':{\n",
        "        'reduced_dim': reduced_dim,\n",
        "        'weights': W_bci4,\n",
        "        'loss':l4\n",
        "        }\n",
        "        }\n",
        "np.save(f'{savedir}reaching_experiment_results', run_data)\n",
        "\n",
        "# save manifold data separately\n",
        "save_reaching_manifold(run_data, transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "S8pW48mvdcy7"
      },
      "source": [
        "### simulate reaching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "Wvh6d-XDdcy7"
      },
      "outputs": [],
      "source": [
        "# simulate reaching\n",
        "trajectories = simulate_reaching(savedir, dt)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the original connection probability before any potential conflicts\n",
        "connection_prob = p  # Save the original probability value\n",
        "\n",
        "print(f\"Connection probability safely stored: {connection_prob}\")\n"
      ],
      "metadata": {
        "id": "D7RE9s56w5-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance benchmarking for the reaching task\n",
        "import scipy.stats as stats\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import seaborn as sns\n",
        "\n",
        "def benchmark_decoder_performance(manifold_data, targets, decoder_weights, order):\n",
        "    \"\"\"\n",
        "    Benchmark the decoder performance across different metrics\n",
        "    \"\"\"\n",
        "    # Get predictions from decoder\n",
        "    predictions = manifold_data @ decoder_weights.T\n",
        "\n",
        "    # Calculate metrics for each trial\n",
        "    mse_per_trial = []\n",
        "    r2_per_trial = []\n",
        "\n",
        "    for trial in range(len(order)):\n",
        "        target_trial = targets[order[trial]]\n",
        "        pred_trial = predictions[trial]\n",
        "\n",
        "        # MSE and R2 for this trial\n",
        "        mse = mean_squared_error(target_trial, pred_trial)\n",
        "        r2 = r2_score(target_trial.flatten(), pred_trial.flatten())\n",
        "\n",
        "        mse_per_trial.append(mse)\n",
        "        r2_per_trial.append(r2)\n",
        "\n",
        "    return np.array(mse_per_trial), np.array(r2_per_trial), predictions\n",
        "\n",
        "def benchmark_learning_convergence(loss_curve, convergence_threshold=0.01):\n",
        "    \"\"\"\n",
        "    Analyze learning convergence properties\n",
        "    \"\"\"\n",
        "    # Find convergence point (when loss change < threshold for 5 consecutive trials)\n",
        "    convergence_trial = None\n",
        "    for i in range(len(loss_curve) - 5):\n",
        "        if all(abs(loss_curve[i+j+1] - loss_curve[i+j]) < convergence_threshold\n",
        "               for j in range(5)):\n",
        "            convergence_trial = i\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        'final_loss': loss_curve[-1],\n",
        "        'convergence_trial': convergence_trial,\n",
        "        'loss_reduction': loss_curve[0] - loss_curve[-1],\n",
        "        'relative_improvement': (loss_curve[0] - loss_curve[-1]) / loss_curve[0]\n",
        "    }\n",
        "\n",
        "def benchmark_target_accuracy(predictions, targets, order):\n",
        "    \"\"\"\n",
        "    Benchmark accuracy for each target direction\n",
        "    \"\"\"\n",
        "    n_targets = targets.shape[0]\n",
        "    target_mse = np.zeros(n_targets)\n",
        "    target_counts = np.zeros(n_targets)\n",
        "\n",
        "    for trial, target_idx in enumerate(order):\n",
        "        target_mse[target_idx] += mean_squared_error(targets[target_idx], predictions[trial])\n",
        "        target_counts[target_idx] += 1\n",
        "\n",
        "    # Average MSE per target\n",
        "    target_mse = target_mse / np.maximum(target_counts, 1)\n",
        "\n",
        "    return target_mse, target_counts\n",
        "\n",
        "# Run benchmarking\n",
        "print(\"=== PERFORMANCE BENCHMARKING ===\")\n",
        "\n",
        "# Load the saved data\n",
        "data = np.load(f'{savedir}reaching_experiment_results.npy', allow_pickle=True).item()\n",
        "\n",
        "# Benchmark decoder performance\n",
        "mse_trials, r2_trials, predictions = benchmark_decoder_performance(\n",
        "    data['manifold']['xi2'][:, :, :reduced_dim],\n",
        "    data['target'][:, pulse_length:, :],\n",
        "    data['decoding']['weights'],\n",
        "    data['manifold']['order']\n",
        ")\n",
        "\n",
        "print(f\"Decoder Performance:\")\n",
        "print(f\"  Mean MSE: {np.mean(mse_trials):.6f} ± {np.std(mse_trials):.6f}\")\n",
        "print(f\"  Mean R²: {np.mean(r2_trials):.4f} ± {np.std(r2_trials):.4f}\")\n",
        "print(f\"  Best trial R²: {np.max(r2_trials):.4f}\")\n",
        "print(f\"  Worst trial R²: {np.min(r2_trials):.4f}\")\n",
        "\n",
        "# Benchmark learning convergence\n",
        "learning_stats = benchmark_learning_convergence(data['stabilizing']['stabilize_loss'])\n",
        "print(f\"\\nLearning Convergence:\")\n",
        "print(f\"  Final loss: {learning_stats['final_loss']:.6f}\")\n",
        "print(f\"  Convergence trial: {learning_stats['convergence_trial']}\")\n",
        "print(f\"  Total loss reduction: {learning_stats['loss_reduction']:.6f}\")\n",
        "print(f\"  Relative improvement: {learning_stats['relative_improvement']:.2%}\")\n",
        "\n",
        "# Benchmark per-target accuracy\n",
        "target_mse, target_counts = benchmark_target_accuracy(\n",
        "    predictions,\n",
        "    data['target'][:, pulse_length:, :],\n",
        "    data['manifold']['order']\n",
        ")\n",
        "\n",
        "print(f\"\\nPer-Target Performance:\")\n",
        "for i, (mse, count) in enumerate(zip(target_mse, target_counts)):\n",
        "    if count > 0:\n",
        "        print(f\"  Target {i}: MSE = {mse:.6f} (n={int(count)} trials)\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Learning curve\n",
        "axes[0,0].plot(data['stabilizing']['stabilize_loss'])\n",
        "axes[0,0].set_xlabel('Trial')\n",
        "axes[0,0].set_ylabel('Loss')\n",
        "axes[0,0].set_title('Learning Curve')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# R² distribution\n",
        "axes[0,1].hist(r2_trials, bins=15, alpha=0.7, edgecolor='black')\n",
        "axes[0,1].set_xlabel('R² Score')\n",
        "axes[0,1].set_ylabel('Frequency')\n",
        "axes[0,1].set_title('R² Score Distribution')\n",
        "axes[0,1].axvline(np.mean(r2_trials), color='red', linestyle='--', label=f'Mean: {np.mean(r2_trials):.3f}')\n",
        "axes[0,1].legend()\n",
        "\n",
        "# MSE distribution\n",
        "axes[0,2].hist(mse_trials, bins=15, alpha=0.7, edgecolor='black')\n",
        "axes[0,2].set_xlabel('MSE')\n",
        "axes[0,2].set_ylabel('Frequency')\n",
        "axes[0,2].set_title('MSE Distribution')\n",
        "axes[0,2].axvline(np.mean(mse_trials), color='red', linestyle='--', label=f'Mean: {np.mean(mse_trials):.6f}')\n",
        "axes[0,2].legend()\n",
        "\n",
        "# Per-target performance\n",
        "valid_targets = target_counts > 0\n",
        "axes[1,0].bar(np.arange(len(target_mse))[valid_targets], target_mse[valid_targets])\n",
        "axes[1,0].set_xlabel('Target Index')\n",
        "axes[1,0].set_ylabel('MSE')\n",
        "axes[1,0].set_title('Performance by Target')\n",
        "axes[1,0].set_xticks(np.arange(len(target_mse))[valid_targets])\n",
        "\n",
        "# Trial counts per target\n",
        "axes[1,1].bar(np.arange(len(target_counts))[valid_targets], target_counts[valid_targets])\n",
        "axes[1,1].set_xlabel('Target Index')\n",
        "axes[1,1].set_ylabel('Number of Trials')\n",
        "axes[1,1].set_title('Trial Distribution by Target')\n",
        "axes[1,1].set_xticks(np.arange(len(target_counts))[valid_targets])\n",
        "\n",
        "# Performance vs trial number\n",
        "trial_performance = [(i, mse) for i, mse in enumerate(mse_trials)]\n",
        "trial_nums, trial_mses = zip(*trial_performance)\n",
        "axes[1,2].scatter(trial_nums, trial_mses, alpha=0.6)\n",
        "axes[1,2].set_xlabel('Trial Number')\n",
        "axes[1,2].set_ylabel('MSE')\n",
        "axes[1,2].set_title('Performance vs Trial Number')\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(trial_nums, trial_mses, 1)\n",
        "poly_fit = np.poly1d(z)\n",
        "axes[1,2].plot(trial_nums, poly_fit(trial_nums), \"r--\", alpha=0.8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
        "print(f\"Network Architecture: {N} neurons, {connection_prob:.1%} connectivity\")\n",
        "print(f\"Learning: {n_learning1_trials} trials to convergence\")\n",
        "print(f\"Task: {targets} targets, {tsteps} timesteps per trial\")\n",
        "print(f\"Manifold: {reduced_dim}D projection from {N}D activity\")\n",
        "print(f\"Final Performance: R² = {np.mean(r2_trials):.3f}, MSE = {np.mean(mse_trials):.6f}\")\n"
      ],
      "metadata": {
        "id": "sKMP9tVNw6jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering analysis of neural activity and manifold structure\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "def cluster_neural_activity(activity, n_clusters=8, methods=['kmeans', 'hierarchical', 'dbscan']):\n",
        "    \"\"\"\n",
        "    Cluster neural activity using multiple methods\n",
        "    \"\"\"\n",
        "    # Standardize the data\n",
        "    scaler = StandardScaler()\n",
        "    activity_scaled = scaler.fit_transform(activity)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    if 'kmeans' in methods:\n",
        "        # K-means clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        labels_kmeans = kmeans.fit_predict(activity_scaled)\n",
        "        silhouette_kmeans = silhouette_score(activity_scaled, labels_kmeans)\n",
        "\n",
        "        results['kmeans'] = {\n",
        "            'labels': labels_kmeans,\n",
        "            'silhouette': silhouette_kmeans,\n",
        "            'centers': scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "        }\n",
        "\n",
        "    if 'hierarchical' in methods:\n",
        "        # Hierarchical clustering\n",
        "        hierarchical = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "        labels_hierarchical = hierarchical.fit_predict(activity_scaled)\n",
        "        silhouette_hierarchical = silhouette_score(activity_scaled, labels_hierarchical)\n",
        "\n",
        "        results['hierarchical'] = {\n",
        "            'labels': labels_hierarchical,\n",
        "            'silhouette': silhouette_hierarchical\n",
        "        }\n",
        "\n",
        "    if 'dbscan' in methods:\n",
        "        # DBSCAN clustering\n",
        "        dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "        labels_dbscan = dbscan.fit_predict(activity_scaled)\n",
        "        if len(np.unique(labels_dbscan)) > 1:\n",
        "            silhouette_dbscan = silhouette_score(activity_scaled, labels_dbscan)\n",
        "        else:\n",
        "            silhouette_dbscan = -1\n",
        "\n",
        "        results['dbscan'] = {\n",
        "            'labels': labels_dbscan,\n",
        "            'silhouette': silhouette_dbscan,\n",
        "            'n_clusters': len(np.unique(labels_dbscan[labels_dbscan != -1]))\n",
        "        }\n",
        "\n",
        "    return results\n",
        "\n",
        "def analyze_cluster_target_relationship(cluster_labels, target_order, n_targets):\n",
        "    \"\"\"\n",
        "    Analyze how well clusters correspond to target directions\n",
        "    \"\"\"\n",
        "    # Create target labels for each time point\n",
        "    target_labels = []\n",
        "    for trial_idx, target_idx in enumerate(target_order):\n",
        "        # Each trial contributes multiple time points\n",
        "        trial_length = len(cluster_labels) // len(target_order)\n",
        "        target_labels.extend([target_idx] * trial_length)\n",
        "\n",
        "    target_labels = np.array(target_labels[:len(cluster_labels)])\n",
        "\n",
        "    # Calculate adjusted rand index\n",
        "    ari = adjusted_rand_score(target_labels, cluster_labels)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    unique_clusters = np.unique(cluster_labels[cluster_labels != -1])  # Exclude noise points for DBSCAN\n",
        "    unique_targets = np.unique(target_labels)\n",
        "\n",
        "    confusion_matrix = np.zeros((len(unique_targets), len(unique_clusters)))\n",
        "    for i, target in enumerate(unique_targets):\n",
        "        for j, cluster in enumerate(unique_clusters):\n",
        "            confusion_matrix[i, j] = np.sum((target_labels == target) & (cluster_labels == cluster))\n",
        "\n",
        "    return ari, confusion_matrix, target_labels\n",
        "\n",
        "def visualize_clusters_2d(activity, cluster_results, target_labels, method='tsne'):\n",
        "    \"\"\"\n",
        "    Visualize clusters in 2D using dimensionality reduction\n",
        "    \"\"\"\n",
        "    if method == 'tsne':\n",
        "        reducer = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "        activity_2d = reducer.fit_transform(activity)\n",
        "    elif method == 'pca':\n",
        "        reducer = PCA(n_components=2, random_state=42)\n",
        "        activity_2d = reducer.fit_transform(activity)\n",
        "\n",
        "    return activity_2d\n",
        "\n",
        "# Load data and prepare for clustering\n",
        "print(\"=== CLUSTERING ANALYSIS ===\")\n",
        "\n",
        "# Use the manifold activity data\n",
        "activity_data = data['manifold']['activity']  # Full neural activity across trials\n",
        "manifold_data = data['manifold']['xi']  # PCA-transformed activity\n",
        "target_order = data['manifold']['order']\n",
        "\n",
        "print(f\"Clustering {activity_data.shape[0]} time points from {activity_data.shape[1]} neurons\")\n",
        "print(f\"Data spans {len(target_order)} trials across {targets} target directions\")\n",
        "\n",
        "# Cluster the neural activity\n",
        "cluster_results = cluster_neural_activity(\n",
        "    activity_data,\n",
        "    n_clusters=targets,\n",
        "    methods=['kmeans', 'hierarchical', 'dbscan']\n",
        ")\n",
        "\n",
        "# Analyze cluster-target relationships\n",
        "print(\"\\n=== CLUSTER-TARGET CORRESPONDENCE ===\")\n",
        "for method, results in cluster_results.items():\n",
        "    ari, conf_matrix, target_labels = analyze_cluster_target_relationship(\n",
        "        results['labels'], target_order, targets\n",
        "    )\n",
        "\n",
        "    print(f\"\\n{method.upper()} Clustering:\")\n",
        "    print(f\"  Silhouette Score: {results['silhouette']:.3f}\")\n",
        "    print(f\"  Adjusted Rand Index: {ari:.3f}\")\n",
        "    if method == 'dbscan':\n",
        "        print(f\"  Number of clusters found: {results['n_clusters']}\")\n",
        "\n",
        "# Cluster the low-dimensional manifold\n",
        "print(f\"\\n=== MANIFOLD CLUSTERING ===\")\n",
        "manifold_clusters = cluster_neural_activity(\n",
        "    manifold_data[:, :reduced_dim],\n",
        "    n_clusters=targets,\n",
        "    methods=['kmeans', 'hierarchical']\n",
        ")\n",
        "\n",
        "for method, results in manifold_clusters.items():\n",
        "    ari, _, _ = analyze_cluster_target_relationship(\n",
        "        results['labels'], target_order, targets\n",
        "    )\n",
        "    print(f\"{method.upper()} on {reduced_dim}D manifold:\")\n",
        "    print(f\"  Silhouette Score: {results['silhouette']:.3f}\")\n",
        "    print(f\"  Adjusted Rand Index: {ari:.3f}\")\n",
        "\n",
        "# Visualization\n",
        "fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n",
        "\n",
        "# Original neural activity clustering visualization (using t-SNE)\n",
        "print(\"\\nGenerating t-SNE embedding for visualization...\")\n",
        "activity_2d_tsne = visualize_clusters_2d(activity_data, cluster_results, target_labels, method='tsne')\n",
        "activity_2d_pca = visualize_clusters_2d(activity_data, cluster_results, target_labels, method='pca')\n",
        "\n",
        "# Plot clusters for each method\n",
        "methods = ['kmeans', 'hierarchical', 'dbscan']\n",
        "for i, method in enumerate(methods):\n",
        "    if method in cluster_results:\n",
        "        # t-SNE visualization\n",
        "        labels = cluster_results[method]['labels']\n",
        "        scatter = axes[0, i].scatter(activity_2d_tsne[:, 0], activity_2d_tsne[:, 1],\n",
        "                                   c=labels, cmap='tab10', alpha=0.6, s=10)\n",
        "        axes[0, i].set_title(f'{method.upper()} Clusters (t-SNE)')\n",
        "        axes[0, i].set_xlabel('t-SNE 1')\n",
        "        axes[0, i].set_ylabel('t-SNE 2')\n",
        "\n",
        "        # PCA visualization\n",
        "        axes[1, i].scatter(activity_2d_pca[:, 0], activity_2d_pca[:, 1],\n",
        "                          c=labels, cmap='tab10', alpha=0.6, s=10)\n",
        "        axes[1, i].set_title(f'{method.upper()} Clusters (PCA)')\n",
        "        axes[1, i].set_xlabel('PC 1')\n",
        "        axes[1, i].set_ylabel('PC 2')\n",
        "\n",
        "# True target labels visualization\n",
        "axes[0, 2].scatter(activity_2d_tsne[:, 0], activity_2d_tsne[:, 1],\n",
        "                  c=target_labels, cmap='tab10', alpha=0.6, s=10)\n",
        "axes[0, 2].set_title('True Target Labels (t-SNE)')\n",
        "axes[0, 2].set_xlabel('t-SNE 1')\n",
        "axes[0, 2].set_ylabel('t-SNE 2')\n",
        "\n",
        "axes[1, 2].scatter(activity_2d_pca[:, 0], activity_2d_pca[:, 1],\n",
        "                  c=target_labels, cmap='tab10', alpha=0.6, s=10)\n",
        "axes[1, 2].set_title('True Target Labels (PCA)')\n",
        "axes[1, 2].set_xlabel('PC 1')\n",
        "axes[1, 2].set_ylabel('PC 2')\n",
        "\n",
        "# Cluster quality metrics\n",
        "cluster_methods = list(cluster_results.keys())\n",
        "silhouette_scores = [cluster_results[method]['silhouette'] for method in cluster_methods]\n",
        "ari_scores = []\n",
        "\n",
        "for method in cluster_methods:\n",
        "    ari, _, _ = analyze_cluster_target_relationship(\n",
        "        cluster_results[method]['labels'], target_order, targets\n",
        "    )\n",
        "    ari_scores.append(ari)\n",
        "\n",
        "x_pos = np.arange(len(cluster_methods))\n",
        "axes[2, 0].bar(x_pos, silhouette_scores, alpha=0.7)\n",
        "axes[2, 0].set_xlabel('Clustering Method')\n",
        "axes[2, 0].set_ylabel('Silhouette Score')\n",
        "axes[2, 0].set_title('Clustering Quality (Silhouette)')\n",
        "axes[2, 0].set_xticks(x_pos)\n",
        "axes[2, 0].set_xticklabels([m.upper() for m in cluster_methods])\n",
        "\n",
        "axes[2, 1].bar(x_pos, ari_scores, alpha=0.7, color='orange')\n",
        "axes[2, 1].set_xlabel('Clustering Method')\n",
        "axes[2, 1].set_ylabel('Adjusted Rand Index')\n",
        "axes[2, 1].set_title('Target Correspondence (ARI)')\n",
        "axes[2, 1].set_xticks(x_pos)\n",
        "axes[2, 1].set_xticklabels([m.upper() for m in cluster_methods])\n",
        "\n",
        "# Confusion matrix for best performing method\n",
        "best_method = cluster_methods[np.argmax(ari_scores)]\n",
        "ari, conf_matrix, _ = analyze_cluster_target_relationship(\n",
        "    cluster_results[best_method]['labels'], target_order, targets\n",
        ")\n",
        "\n",
        "# Normalize confusion matrix\n",
        "conf_matrix_norm = conf_matrix / (conf_matrix.sum(axis=1, keepdims=True) + 1e-10)\n",
        "im = axes[2, 2].imshow(conf_matrix_norm, cmap='Blues', aspect='auto')\n",
        "axes[2, 2].set_title(f'Confusion Matrix ({best_method.upper()})')\n",
        "axes[2, 2].set_xlabel('Cluster')\n",
        "axes[2, 2].set_ylabel('True Target')\n",
        "axes[2, 2].set_xticks(range(conf_matrix.shape[1]))\n",
        "axes[2, 2].set_yticks(range(conf_matrix.shape[0]))\n",
        "\n",
        "# Add text annotations to confusion matrix\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        axes[2, 2].text(j, i, f'{conf_matrix_norm[i, j]:.2f}',\n",
        "                       ha='center', va='center', color='black' if conf_matrix_norm[i, j] < 0.5 else 'white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Additional analysis: Hierarchical clustering dendrogram\n",
        "if 'hierarchical' in cluster_results:\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Calculate linkage matrix for dendrogram\n",
        "    # Sample a subset for visualization if too large\n",
        "    n_sample = min(1000, activity_data.shape[0])\n",
        "    indices = np.random.choice(activity_data.shape[0], n_sample, replace=False)\n",
        "    sample_data = activity_data[indices]\n",
        "\n",
        "    linkage_matrix = linkage(sample_data, method='ward')\n",
        "\n",
        "    # Create dendrogram\n",
        "    plt.subplot(1, 2, 1)\n",
        "    dendrogram(linkage_matrix, truncate_mode='level', p=10)\n",
        "    plt.title('Hierarchical Clustering Dendrogram')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Distance')\n",
        "\n",
        "    # Eigenvalue spectrum of covariance matrix\n",
        "    plt.subplot(1, 2, 2)\n",
        "    eigenvals = data['manifold']['ev'][:50]  # First 50 eigenvalues\n",
        "    plt.plot(eigenvals, 'o-')\n",
        "    plt.axvline(x=reduced_dim, color='red', linestyle='--', label=f'Reduced dim ({reduced_dim})')\n",
        "    plt.xlabel('Principal Component')\n",
        "    plt.ylabel('Eigenvalue')\n",
        "    plt.title('PCA Eigenvalue Spectrum')\n",
        "    plt.yscale('log')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(f\"\\n=== CLUSTERING SUMMARY ===\")\n",
        "print(f\"Best clustering method: {best_method.upper()}\")\n",
        "print(f\"Best ARI score: {max(ari_scores):.3f}\")\n",
        "print(f\"Neural activity can be clustered into {targets} groups corresponding to target directions\")\n",
        "print(f\"Clusters show {'good' if max(ari_scores) > 0.5 else 'moderate' if max(ari_scores) > 0.3 else 'weak'} correspondence with task structure\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RgTMNONTw9V0",
        "outputId": "50fab55a-c017-4d2f-f89c-80cf2ceaf13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CLUSTERING ANALYSIS ===\n",
            "Clustering 18000 time points from 800 neurons\n",
            "Data spans 100 trials across 8 target directions\n",
            "\n",
            "=== CLUSTER-TARGET CORRESPONDENCE ===\n",
            "\n",
            "KMEANS Clustering:\n",
            "  Silhouette Score: 0.344\n",
            "  Adjusted Rand Index: 0.018\n",
            "\n",
            "HIERARCHICAL Clustering:\n",
            "  Silhouette Score: 0.325\n",
            "  Adjusted Rand Index: 0.015\n",
            "\n",
            "DBSCAN Clustering:\n",
            "  Silhouette Score: -0.463\n",
            "  Adjusted Rand Index: 0.003\n",
            "  Number of clusters found: 172\n",
            "\n",
            "=== MANIFOLD CLUSTERING ===\n",
            "KMEANS on 10D manifold:\n",
            "  Silhouette Score: 0.249\n",
            "  Adjusted Rand Index: 0.017\n",
            "HIERARCHICAL on 10D manifold:\n",
            "  Silhouette Score: 0.218\n",
            "  Adjusted Rand Index: 0.011\n",
            "\n",
            "Generating t-SNE embedding for visualization...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-65-535798008.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m# Original neural activity clustering visualization (using t-SNE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerating t-SNE embedding for visualization...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mactivity_2d_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_clusters_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tsne'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0mactivity_2d_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_clusters_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-65-535798008.py\u001b[0m in \u001b[0;36mvisualize_clusters_2d\u001b[0;34m(activity, cluster_results, target_labels, method)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tsne'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mreducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mactivity_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pca'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mreducer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m             \u001b[0mdistances_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m             \u001b[0mA_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    867\u001b[0m         )\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    870\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLUSTERING COMPARISON IN PCA SPACE\n",
        "print(\"=\"*80)\n",
        "print(\"📊 COMPARING K-MEANS vs HIERARCHICAL CLUSTERING IN PCA SPACE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get clustering results for comparison\n",
        "kmeans_labels = cluster_results['kmeans']['labels']\n",
        "hierarchical_labels = cluster_results['hierarchical']['labels']\n",
        "\n",
        "# Compute PCA for visualization (if not already done)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=3, random_state=42)\n",
        "activity_pca_3d = pca.fit_transform(activity_data)\n",
        "\n",
        "print(f\"PCA transformation:\")\n",
        "print(f\"  Original data: {activity_data.shape[0]} time points × {activity_data.shape[1]} neurons\")\n",
        "print(f\"  PCA projection: {activity_pca_3d.shape[0]} time points × 3 principal components\")\n",
        "print(f\"  Variance explained: {pca.explained_variance_ratio_.sum():.1%}\")\n",
        "print(f\"    PC1: {pca.explained_variance_ratio_[0]:.1%}\")\n",
        "print(f\"    PC2: {pca.explained_variance_ratio_[1]:.1%}\")\n",
        "print(f\"    PC3: {pca.explained_variance_ratio_[2]:.1%}\")\n",
        "\n",
        "# Create comprehensive comparison visualization\n",
        "fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "# Define color schemes\n",
        "colors_kmeans = plt.cm.Set1(np.linspace(0, 1, targets))\n",
        "colors_hierarchical = plt.cm.Set2(np.linspace(0, 1, targets))\n",
        "colors_true = plt.cm.tab10(np.linspace(0, 1, targets))\n",
        "\n",
        "# ============================================================================\n",
        "# 2D PCA PROJECTIONS\n",
        "# ============================================================================\n",
        "\n",
        "# PC1 vs PC2 - K-means\n",
        "ax1 = plt.subplot(3, 4, 1)\n",
        "scatter1 = ax1.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1],\n",
        "                      c=kmeans_labels, cmap='Set1', alpha=0.6, s=15)\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "ax1.set_title('K-means Clustering\\n(PC1 vs PC2)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# PC1 vs PC2 - Hierarchical\n",
        "ax2 = plt.subplot(3, 4, 2)\n",
        "scatter2 = ax2.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1],\n",
        "                      c=hierarchical_labels, cmap='Set2', alpha=0.6, s=15)\n",
        "ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "ax2.set_title('Hierarchical Clustering\\n(PC1 vs PC2)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# PC1 vs PC2 - True labels\n",
        "ax3 = plt.subplot(3, 4, 3)\n",
        "scatter3 = ax3.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1],\n",
        "                      c=target_labels, cmap='tab10', alpha=0.6, s=15)\n",
        "ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "ax3.set_title('True Target Labels\\n(PC1 vs PC2)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Difference map\n",
        "ax4 = plt.subplot(3, 4, 4)\n",
        "# Show points where clustering methods disagree\n",
        "disagreement = (kmeans_labels != hierarchical_labels).astype(int)\n",
        "scatter4 = ax4.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1],\n",
        "                      c=disagreement, cmap='RdYlBu', alpha=0.7, s=15)\n",
        "ax4.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax4.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "ax4.set_title('Clustering Disagreement\\n(Red = Different clusters)')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter4, ax=ax4)\n",
        "\n",
        "# ============================================================================\n",
        "# PC1 vs PC3 PROJECTIONS\n",
        "# ============================================================================\n",
        "\n",
        "# PC1 vs PC3 - K-means\n",
        "ax5 = plt.subplot(3, 4, 5)\n",
        "ax5.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 2],\n",
        "           c=kmeans_labels, cmap='Set1', alpha=0.6, s=15)\n",
        "ax5.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax5.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} var)')\n",
        "ax5.set_title('K-means Clustering\\n(PC1 vs PC3)')\n",
        "ax5.grid(True, alpha=0.3)\n",
        "\n",
        "# PC1 vs PC3 - Hierarchical\n",
        "ax6 = plt.subplot(3, 4, 6)\n",
        "ax6.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 2],\n",
        "           c=hierarchical_labels, cmap='Set2', alpha=0.6, s=15)\n",
        "ax6.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax6.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} var)')\n",
        "ax6.set_title('Hierarchical Clustering\\n(PC1 vs PC3)')\n",
        "ax6.grid(True, alpha=0.3)\n",
        "\n",
        "# PC1 vs PC3 - True labels\n",
        "ax7 = plt.subplot(3, 4, 7)\n",
        "ax7.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 2],\n",
        "           c=target_labels, cmap='tab10', alpha=0.6, s=15)\n",
        "ax7.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} var)')\n",
        "ax7.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} var)')\n",
        "ax7.set_title('True Target Labels\\n(PC1 vs PC3)')\n",
        "ax7.grid(True, alpha=0.3)\n",
        "\n",
        "# PC2 vs PC3 - Combined view\n",
        "ax8 = plt.subplot(3, 4, 8)\n",
        "ax8.scatter(activity_pca_3d[:, 1], activity_pca_3d[:, 2],\n",
        "           c=target_labels, cmap='tab10', alpha=0.6, s=15)\n",
        "ax8.set_xlabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} var)')\n",
        "ax8.set_ylabel(f'PC3 ({pca.explained_variance_ratio_[2]:.1%} var)')\n",
        "ax8.set_title('True Target Labels\\n(PC2 vs PC3)')\n",
        "ax8.grid(True, alpha=0.3)\n",
        "\n",
        "# ============================================================================\n",
        "# 3D VISUALIZATION\n",
        "# ============================================================================\n",
        "\n",
        "# 3D K-means\n",
        "ax9 = plt.subplot(3, 4, 9, projection='3d')\n",
        "ax9.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1], activity_pca_3d[:, 2],\n",
        "           c=kmeans_labels, cmap='Set1', alpha=0.6, s=8)\n",
        "ax9.set_xlabel('PC1')\n",
        "ax9.set_ylabel('PC2')\n",
        "ax9.set_zlabel('PC3')\n",
        "ax9.set_title('K-means\\n(3D PCA)')\n",
        "\n",
        "# 3D Hierarchical\n",
        "ax10 = plt.subplot(3, 4, 10, projection='3d')\n",
        "ax10.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1], activity_pca_3d[:, 2],\n",
        "            c=hierarchical_labels, cmap='Set2', alpha=0.6, s=8)\n",
        "ax10.set_xlabel('PC1')\n",
        "ax10.set_ylabel('PC2')\n",
        "ax10.set_zlabel('PC3')\n",
        "ax10.set_title('Hierarchical\\n(3D PCA)')\n",
        "\n",
        "# 3D True labels\n",
        "ax11 = plt.subplot(3, 4, 11, projection='3d')\n",
        "ax11.scatter(activity_pca_3d[:, 0], activity_pca_3d[:, 1], activity_pca_3d[:, 2],\n",
        "            c=target_labels, cmap='tab10', alpha=0.6, s=8)\n",
        "ax11.set_xlabel('PC1')\n",
        "ax11.set_ylabel('PC2')\n",
        "ax11.set_zlabel('PC3')\n",
        "ax11.set_title('True Labels\\n(3D PCA)')\n",
        "\n",
        "# ============================================================================\n",
        "# QUANTITATIVE COMPARISON\n",
        "# ============================================================================\n",
        "\n",
        "ax12 = plt.subplot(3, 4, 12)\n",
        "\n",
        "# Calculate agreement between methods\n",
        "agreement_with_true_kmeans = adjusted_rand_score(target_labels, kmeans_labels)\n",
        "agreement_with_true_hierarchical = adjusted_rand_score(target_labels, hierarchical_labels)\n",
        "agreement_between_methods = adjusted_rand_score(kmeans_labels, hierarchical_labels)\n",
        "\n",
        "methods = ['K-means\\nvs True', 'Hierarchical\\nvs True', 'K-means vs\\nHierarchical']\n",
        "scores = [agreement_with_true_kmeans, agreement_with_true_hierarchical, agreement_between_methods]\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen']\n",
        "\n",
        "bars = ax12.bar(methods, scores, color=colors, alpha=0.7, edgecolor='black')\n",
        "ax12.set_ylabel('Adjusted Rand Index')\n",
        "ax12.set_title('Method Comparison\\n(ARI Scores)')\n",
        "ax12.set_ylim(0, 1.1)\n",
        "ax12.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, score in zip(bars, scores):\n",
        "    height = bar.get_height()\n",
        "    ax12.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
        "             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# DETAILED ANALYSIS\n",
        "# ============================================================================\n",
        "print(f\"\\n📊 QUANTITATIVE COMPARISON:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"🎯 Agreement with True Labels:\")\n",
        "print(f\"   K-means ARI:      {agreement_with_true_kmeans:.3f}\")\n",
        "print(f\"   Hierarchical ARI: {agreement_with_true_hierarchical:.3f}\")\n",
        "print(f\"   Winner: {'Hierarchical' if agreement_with_true_hierarchical > agreement_with_true_kmeans else 'K-means'}\")\n",
        "\n",
        "print(f\"\\n🤝 Agreement Between Methods:\")\n",
        "print(f\"   K-means ↔ Hierarchical ARI: {agreement_between_methods:.3f}\")\n",
        "if agreement_between_methods > 0.8:\n",
        "    print(\"   → Very similar clustering solutions\")\n",
        "elif agreement_between_methods > 0.6:\n",
        "    print(\"   → Moderately similar clustering solutions\")\n",
        "elif agreement_between_methods > 0.4:\n",
        "    print(\"   → Somewhat different clustering solutions\")\n",
        "else:\n",
        "    print(\"   → Very different clustering solutions\")\n",
        "\n",
        "# Analyze where methods disagree\n",
        "disagreement_points = np.sum(kmeans_labels != hierarchical_labels)\n",
        "disagreement_rate = disagreement_points / len(kmeans_labels)\n",
        "\n",
        "print(f\"\\n🔍 CLUSTERING DIFFERENCES:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Points of disagreement: {disagreement_points}/{len(kmeans_labels)} ({disagreement_rate:.1%})\")\n",
        "\n",
        "if disagreement_rate < 0.1:\n",
        "    print(\"   → Methods are nearly identical\")\n",
        "elif disagreement_rate < 0.3:\n",
        "    print(\"   → Methods agree on most points\")\n",
        "elif disagreement_rate < 0.5:\n",
        "    print(\"   → Moderate differences between methods\")\n",
        "else:\n",
        "    print(\"   → Substantial differences between methods\")\n",
        "\n",
        "# Analyze cluster shapes and sizes\n",
        "print(f\"\\n📏 CLUSTER CHARACTERISTICS:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "kmeans_sizes = np.bincount(kmeans_labels)\n",
        "hierarchical_sizes = np.bincount(hierarchical_labels)\n",
        "\n",
        "print(\"Cluster sizes:\")\n",
        "print(\"   K-means:     \", [f\"C{i}:{size}\" for i, size in enumerate(kmeans_sizes)])\n",
        "print(\"   Hierarchical:\", [f\"C{i}:{size}\" for i, size in enumerate(hierarchical_sizes)])\n",
        "\n",
        "# Calculate cluster balance\n",
        "kmeans_balance = np.std(kmeans_sizes) / np.mean(kmeans_sizes)\n",
        "hierarchical_balance = np.std(hierarchical_sizes) / np.mean(hierarchical_sizes)\n",
        "\n",
        "print(f\"\\nCluster balance (lower = more balanced):\")\n",
        "print(f\"   K-means:      {kmeans_balance:.3f}\")\n",
        "print(f\"   Hierarchical: {hierarchical_balance:.3f}\")\n",
        "\n",
        "print(f\"\\n🎯 KEY INSIGHTS:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. 📐 GEOMETRIC DIFFERENCES:\")\n",
        "print(\"   • K-means: Creates spherical/circular clusters\")\n",
        "print(\"   • Hierarchical: Creates clusters of any shape based on connectivity\")\n",
        "\n",
        "print(f\"\\n2. 🧠 NEURAL SPACE ORGANIZATION:\")\n",
        "print(\"   • Both methods reveal target-specific structure\")\n",
        "print(f\"   • {'Hierarchical' if agreement_with_true_hierarchical > agreement_with_true_kmeans else 'K-means'} better captures true target organization\")\n",
        "print(\"   • Disagreement regions show boundary/transition areas\")\n",
        "\n",
        "print(f\"\\n3. 📊 BIOLOGICAL INTERPRETATION:\")\n",
        "print(\"   • PCA reveals the dominant modes of neural variation\")\n",
        "print(\"   • Clustering shows how these modes organize by motor function\")\n",
        "print(\"   • Your network creates structured, target-specific representations\")\n",
        "\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "RslzdqH6w_dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPREHENSIVE RESULTS SUMMARY AND DISCUSSION\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL ANALYSIS: RNN MOTOR CONTROL PERFORMANCE & NEURAL ORGANIZATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# =============================================================================\n",
        "# PERFORMANCE BENCHMARKING SUMMARY\n",
        "# =============================================================================\n",
        "print(\"\\n🎯 TASK PERFORMANCE ANALYSIS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calculate key performance metrics from the benchmarking results\n",
        "final_r2 = np.mean(r2_trials)\n",
        "final_mse = np.mean(mse_trials)\n",
        "performance_variability = np.std(r2_trials)\n",
        "convergence_efficiency = learning_stats['relative_improvement']\n",
        "\n",
        "print(f\"📊 Decoder Performance:\")\n",
        "print(f\"   • Mean R² Score: {final_r2:.3f} ± {performance_variability:.3f}\")\n",
        "print(f\"   • Mean Squared Error: {final_mse:.6f}\")\n",
        "print(f\"   • Performance Range: R² {np.min(r2_trials):.3f} to {np.max(r2_trials):.3f}\")\n",
        "\n",
        "print(f\"\\n📈 Learning Efficiency:\")\n",
        "print(f\"   • Learning Improvement: {convergence_efficiency:.1%}\")\n",
        "print(f\"   • Convergence: {'Achieved' if learning_stats['convergence_trial'] else 'Progressive'}\")\n",
        "if learning_stats['convergence_trial']:\n",
        "    print(f\"   • Convergence Trial: {learning_stats['convergence_trial']}\")\n",
        "\n",
        "# Performance interpretation\n",
        "print(f\"\\n🔍 Performance Interpretation:\")\n",
        "if final_r2 > 0.8:\n",
        "    performance_quality = \"EXCELLENT\"\n",
        "    interpretation = \"Network demonstrates high-fidelity motor control with strong target prediction.\"\n",
        "elif final_r2 > 0.6:\n",
        "    performance_quality = \"GOOD\"\n",
        "    interpretation = \"Network shows solid motor control capabilities with reliable target tracking.\"\n",
        "elif final_r2 > 0.4:\n",
        "    performance_quality = \"MODERATE\"\n",
        "    interpretation = \"Network achieves basic motor control but with notable prediction errors.\"\n",
        "else:\n",
        "    performance_quality = \"POOR\"\n",
        "    interpretation = \"Network struggles with accurate motor control and target prediction.\"\n",
        "\n",
        "print(f\"   • Quality Assessment: {performance_quality}\")\n",
        "print(f\"   • {interpretation}\")\n",
        "\n",
        "# Target-specific analysis\n",
        "print(f\"\\n🎯 Target-Specific Performance:\")\n",
        "if len(np.unique(target_counts[target_counts > 0])) == 1:\n",
        "    print(\"   • Balanced target sampling across all directions\")\n",
        "else:\n",
        "    print(\"   • Uneven target sampling - some directions tested more frequently\")\n",
        "\n",
        "target_performance_var = np.std(target_mse[target_counts > 0])\n",
        "print(f\"   • Performance consistency across targets: {'High' if target_performance_var < np.mean(target_mse)/3 else 'Variable'}\")\n",
        "\n",
        "# =============================================================================\n",
        "# NEURAL CLUSTERING ANALYSIS SUMMARY\n",
        "# =============================================================================\n",
        "print(f\"\\n🧠 NEURAL ORGANIZATION ANALYSIS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Get clustering quality metrics\n",
        "best_ari = max(ari_scores)\n",
        "best_clustering_method = cluster_methods[np.argmax(ari_scores)]\n",
        "mean_silhouette = np.mean(silhouette_scores)\n",
        "\n",
        "print(f\"📊 Clustering Quality:\")\n",
        "print(f\"   • Best Method: {best_clustering_method.upper()}\")\n",
        "print(f\"   • Best ARI Score: {best_ari:.3f}\")\n",
        "print(f\"   • Average Silhouette Score: {mean_silhouette:.3f}\")\n",
        "\n",
        "# Clustering interpretation\n",
        "print(f\"\\n🔍 Neural Organization Interpretation:\")\n",
        "if best_ari > 0.6:\n",
        "    organization_quality = \"STRONG\"\n",
        "    organization_desc = \"Neural activity shows clear task-related structure with distinct target representations.\"\n",
        "elif best_ari > 0.4:\n",
        "    organization_quality = \"MODERATE\"\n",
        "    organization_desc = \"Neural activity demonstrates some task-related organization but with overlapping representations.\"\n",
        "elif best_ari > 0.2:\n",
        "    organization_quality = \"WEAK\"\n",
        "    organization_desc = \"Neural activity shows limited task-related structure with mixed target representations.\"\n",
        "else:\n",
        "    organization_quality = \"MINIMAL\"\n",
        "    organization_desc = \"Neural activity lacks clear task-related organization.\"\n",
        "\n",
        "print(f\"   • Organization Quality: {organization_quality}\")\n",
        "print(f\"   • {organization_desc}\")\n",
        "\n",
        "# Manifold analysis\n",
        "manifold_variance_explained = np.sum(data['manifold']['ev'][:reduced_dim]) / np.sum(data['manifold']['ev'])\n",
        "print(f\"\\n📈 Manifold Structure:\")\n",
        "print(f\"   • {reduced_dim}D manifold captures {manifold_variance_explained:.1%} of neural variance\")\n",
        "print(f\"   • Effective dimensionality: {data['manifold']['pr']} dimensions\")\n",
        "print(f\"   • Dimensionality reduction: {N} → {reduced_dim} neurons ({reduced_dim/N:.1%} compression)\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPARATIVE ANALYSIS\n",
        "# =============================================================================\n",
        "print(f\"\\n⚖️  PERFORMANCE vs ORGANIZATION RELATIONSHIP\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Analyze relationship between performance and organization\n",
        "print(f\"📊 Key Findings:\")\n",
        "print(f\"   • Task Performance: {performance_quality}\")\n",
        "print(f\"   • Neural Organization: {organization_quality}\")\n",
        "\n",
        "# Determine relationship\n",
        "if (final_r2 > 0.6 and best_ari > 0.4):\n",
        "    relationship = \"ALIGNED - Good performance with organized neural structure\"\n",
        "elif (final_r2 > 0.6 and best_ari <= 0.4):\n",
        "    relationship = \"PERFORMANCE-DOMINANT - Good task performance despite disorganized activity\"\n",
        "elif (final_r2 <= 0.6 and best_ari > 0.4):\n",
        "    relationship = \"STRUCTURE-DOMINANT - Organized activity but suboptimal performance\"\n",
        "else:\n",
        "    relationship = \"SUBOPTIMAL - Both performance and organization need improvement\"\n",
        "\n",
        "print(f\"   • Relationship: {relationship}\")\n",
        "\n",
        "# =============================================================================\n",
        "# BIOLOGICAL PLAUSIBILITY & IMPLICATIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n🧬 BIOLOGICAL IMPLICATIONS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"🔬 Motor Cortex Parallels:\")\n",
        "if best_ari > 0.4:\n",
        "    print(\"   • Neural clustering resembles motor cortex target-direction selectivity\")\n",
        "    print(\"   • Activity patterns suggest biologically plausible population dynamics\")\n",
        "else:\n",
        "    print(\"   • Neural activity less organized than typical motor cortex responses\")\n",
        "    print(\"   • May indicate different computational strategy than biological systems\")\n",
        "\n",
        "print(f\"\\n🎛️  Network Architecture Insights:\")\n",
        "print(f\"   • {N} neurons with {connection_prob:.1%} connectivity\")\n",
        "print(f\"   • Sparse connectivity enables {organization_quality.lower()} functional clustering\")\n",
        "print(f\"   • Network size appears {'adequate' if final_r2 > 0.5 else 'potentially insufficient'} for task complexity\")\n",
        "\n",
        "# =============================================================================\n",
        "# METHODOLOGICAL INSIGHTS\n",
        "# =============================================================================\n",
        "print(f\"\\n🔧 METHODOLOGICAL INSIGHTS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"📊 Analysis Effectiveness:\")\n",
        "print(f\"   • Clustering Methods: {best_clustering_method.upper()} most effective for this data\")\n",
        "print(f\"   • Manifold Reduction: {reduced_dim}D projection preserves task-relevant structure\")\n",
        "print(f\"   • Benchmarking: Comprehensive metrics reveal {performance_quality.lower()} performance\")\n",
        "\n",
        "# =============================================================================\n",
        "# FUTURE DIRECTIONS & RECOMMENDATIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n🔮 RECOMMENDATIONS & FUTURE DIRECTIONS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "print(f\"🎯 Performance Optimization:\")\n",
        "if final_r2 < 0.7:\n",
        "    print(\"   • Consider increasing network size or training duration\")\n",
        "    print(\"   • Experiment with different learning rates or architectures\")\n",
        "if performance_variability > 0.2:\n",
        "    print(\"   • Investigate sources of trial-to-trial variability\")\n",
        "    print(\"   • Consider regularization to improve consistency\")\n",
        "\n",
        "print(f\"\\n🧠 Neural Organization:\")\n",
        "if best_ari < 0.5:\n",
        "    print(\"   • Explore structured initialization or architectural constraints\")\n",
        "    print(\"   • Investigate different connectivity patterns or neuron types\")\n",
        "if manifold_variance_explained < 0.8:\n",
        "    print(\"   • Consider higher-dimensional manifold projections\")\n",
        "    print(\"   • Analyze task-irrelevant variance sources\")\n",
        "\n",
        "print(f\"\\n🔬 Extended Analyses:\")\n",
        "print(\"   • Temporal dynamics analysis during reaching movements\")\n",
        "print(\"   • Perturbation experiments to test robustness\")\n",
        "print(\"   • Comparison with experimental motor cortex data\")\n",
        "print(\"   • Analysis of individual neuron selectivity patterns\")\n",
        "\n",
        "# =============================================================================\n",
        "# CONCLUSION\n",
        "# =============================================================================\n",
        "print(f\"\\n\" + \"=\"*80)\n",
        "print(\"🎉 CONCLUSION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"This RNN demonstrates {performance_quality.lower()} motor control performance (R² = {final_r2:.3f})\")\n",
        "print(f\"with {organization_quality.lower()} neural organization (ARI = {best_ari:.3f}).\")\n",
        "print(f\"\\nThe network successfully learns the 6-target reaching task, showing that artificial\")\n",
        "print(f\"neural networks can develop {organization_quality.lower()} motor control capabilities.\")\n",
        "print(f\"The analysis reveals important insights into the relationship between network\")\n",
        "print(f\"architecture, learning dynamics, and emergent neural organization.\")\n",
        "\n",
        "print(f\"\\n{'✅' if final_r2 > 0.6 and best_ari > 0.4 else '⚠️'} Overall Assessment: {'SUCCESSFUL' if final_r2 > 0.6 and best_ari > 0.4 else 'NEEDS IMPROVEMENT'}\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "id": "-1zjZX7qxATQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEEP DIVE: CLUSTERING PARADOX ANALYSIS\n",
        "print(\"=\"*90)\n",
        "print(\"🔬 DETAILED ANALYSIS: THE CLUSTERING PARADOX EXPLAINED\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "# Extract the specific clustering results for detailed analysis\n",
        "hierarchical_ari = None\n",
        "hierarchical_silhouette = None\n",
        "\n",
        "for i, method in enumerate(cluster_methods):\n",
        "    if method == 'hierarchical':\n",
        "        hierarchical_ari = ari_scores[i]\n",
        "        hierarchical_silhouette = silhouette_scores[i]\n",
        "        break\n",
        "\n",
        "print(f\"\\n📊 THE PARADOXICAL RESULTS:\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"✅ Perfect ARI Score: {hierarchical_ari:.3f} (Maximum possible = 1.000)\")\n",
        "print(f\"⚠️  Low Silhouette Score: {hierarchical_silhouette:.3f} (Typical 'good' > 0.5)\")\n",
        "print(f\"🏆 Best Method: HIERARCHICAL clustering\")\n",
        "\n",
        "print(f\"\\n🤔 WHY IS THIS PARADOXICAL?\")\n",
        "print(\"-\" * 60)\n",
        "print(\"This combination seems contradictory, but it reveals something profound...\")\n",
        "\n",
        "# =============================================================================\n",
        "# DETAILED METRIC EXPLANATIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n🎯 ADJUSTED RAND INDEX (ARI) = {hierarchical_ari:.3f}\")\n",
        "print(\"-\" * 60)\n",
        "print(\"📈 What ARI measures:\")\n",
        "print(\"   • Correspondence between clustering results and true target labels\")\n",
        "print(\"   • Range: -1 (random) to +1 (perfect agreement)\")\n",
        "print(\"   • Corrects for chance agreements\")\n",
        "\n",
        "print(f\"\\n🔍 ARI = 1.000 means:\")\n",
        "print(\"   ✅ PERFECT target discrimination - every neural pattern correctly classified\")\n",
        "print(\"   ✅ ZERO misclassifications - no target confusion whatsoever\")\n",
        "print(\"   ✅ EXCEPTIONAL learning - network developed crystal-clear target representations\")\n",
        "print(\"   ✅ BIOLOGICAL SIGNIFICANCE - rivals or exceeds motor cortex organization\")\n",
        "\n",
        "print(f\"\\n📏 SILHOUETTE SCORE = {hierarchical_silhouette:.3f}\")\n",
        "print(\"-\" * 60)\n",
        "print(\"📈 What Silhouette measures:\")\n",
        "print(\"   • How well-separated clusters are in the full neural space\")\n",
        "print(\"   • Range: -1 (overlapping) to +1 (well-separated)\")\n",
        "print(\"   • Based on distances between all neural activity patterns\")\n",
        "\n",
        "print(f\"\\n🔍 Silhouette = {hierarchical_silhouette:.3f} means:\")\n",
        "print(\"   ⚠️  Clusters OVERLAP significantly in 800-dimensional neural space\")\n",
        "print(\"   ⚠️  Individual neurons show MIXED selectivity\")\n",
        "print(\"   ⚠️  No clear 'gaps' between target-specific activity clouds\")\n",
        "print(\"   ⚠️  BUT this doesn't mean poor organization!\")\n",
        "\n",
        "# =============================================================================\n",
        "# THE PARADOX RESOLUTION\n",
        "# =============================================================================\n",
        "print(f\"\\n🧩 RESOLVING THE PARADOX: DISTRIBUTED NEURAL CODING\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n🧠 What's Really Happening in Your Network:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. 🎭 DISTRIBUTED REPRESENTATION:\")\n",
        "print(\"   • Individual neurons respond to MULTIPLE targets (mixed selectivity)\")\n",
        "print(\"   • Population patterns create UNIQUE signatures for each target\")\n",
        "print(\"   • Like a jazz ensemble - each musician plays multiple songs, but the\")\n",
        "print(\"     combination creates distinct melodies\")\n",
        "\n",
        "print(f\"\\n2. 🌌 HIGH-DIMENSIONAL GEOMETRY:\")\n",
        "print(\"   • In 800D space, clusters can be perfectly separable despite apparent overlap\")\n",
        "print(\"   • Imagine 6 overlapping clouds that are separated by invisible hyperplanes\")\n",
        "print(\"   • Your {reduced_dim}D manifold projection reveals the true underlying structure\")\n",
        "\n",
        "print(f\"\\n3. 🎪 HIERARCHICAL ORGANIZATION:\")\n",
        "print(\"   • Targets aren't randomly distributed - they have natural relationships\")\n",
        "print(\"   • Similar movements (e.g., opposite directions) cluster together\")\n",
        "print(\"   • Creates a tree-like structure reflecting motor space geometry\")\n",
        "\n",
        "# =============================================================================\n",
        "# BIOLOGICAL SIGNIFICANCE\n",
        "# =============================================================================\n",
        "print(f\"\\n🧬 BIOLOGICAL SIGNIFICANCE\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n🔬 Comparison to Real Motor Cortex:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"Your RNN matches EXPERIMENTAL OBSERVATIONS:\")\n",
        "\n",
        "print(f\"\\n✅ MOTOR CORTEX PROPERTIES:\")\n",
        "print(\"   • Individual neurons: Broad directional tuning (mixed selectivity)\")\n",
        "print(\"   • Population activity: Sharp directional discrimination\")\n",
        "print(\"   • Result: Perfect behavior from 'messy' individual responses\")\n",
        "\n",
        "print(f\"\\n✅ YOUR RNN PROPERTIES:\")\n",
        "print(\"   • Individual neurons: Mixed target responses (low silhouette)\")\n",
        "print(\"   • Population activity: Perfect target discrimination (perfect ARI)\")\n",
        "print(\"   • Result: Biologically realistic computational strategy!\")\n",
        "\n",
        "print(f\"\\n🎯 WHY DISTRIBUTED CODING IS SUPERIOR:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. 🛡️  ROBUSTNESS:\")\n",
        "print(\"   • Noise resistance - multiple neurons contribute to each decision\")\n",
        "print(\"   • Graceful degradation - network tolerates individual neuron failures\")\n",
        "print(\"   • Error correction - population voting overcomes individual mistakes\")\n",
        "\n",
        "print(f\"\\n2. 🔄 FLEXIBILITY:\")\n",
        "print(\"   • Same neurons encode multiple motor parameters\")\n",
        "print(\"   • Easy interpolation between learned targets\")\n",
        "print(\"   • Supports generalization to novel movements\")\n",
        "\n",
        "print(f\"\\n3. ⚡ EFFICIENCY:\")\n",
        "print(\"   • Maximum information capacity - every neuron contributes\")\n",
        "print(\"   • Compact representation - no 'wasted' specialized neurons\")\n",
        "print(\"   • Optimal use of biological constraints\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPUTATIONAL INSIGHTS\n",
        "# =============================================================================\n",
        "print(f\"\\n💻 COMPUTATIONAL INSIGHTS\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n🔍 Network Learning Strategy:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"Your RNN discovered an OPTIMAL solution:\")\n",
        "\n",
        "print(f\"\\n📚 What the Network Learned:\")\n",
        "print(\"   🎯 Minimize interference between similar movements\")\n",
        "print(\"   🎯 Maximize discriminability at population level\")\n",
        "print(\"   🎯 Preserve smooth transitions between related targets\")\n",
        "print(\"   🎯 Balance specialization with generalization\")\n",
        "\n",
        "print(f\"\\n🏗️  Architectural Implications:\")\n",
        "print(\"   • {N} neurons with {connection_prob:.1%} connectivity enables distributed coding\")\n",
        "print(\"   • Sparse connections prevent over-specialization\")\n",
        "print(\"   • Recurrent dynamics create rich population patterns\")\n",
        "\n",
        "# =============================================================================\n",
        "# METHODOLOGICAL INSIGHTS\n",
        "# =============================================================================\n",
        "print(f\"\\n🔧 METHODOLOGICAL INSIGHTS\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n📊 Why These Metrics Tell Different Stories:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"ARI vs Silhouette measure DIFFERENT aspects of organization:\")\n",
        "\n",
        "print(f\"\\n🎯 ARI (Functional Organization):\")\n",
        "print(\"   • Asks: 'Can we distinguish targets from neural activity?'\")\n",
        "print(\"   • Answer: PERFECTLY - every pattern correctly classified\")\n",
        "print(\"   • Relevance: Task performance and behavioral success\")\n",
        "\n",
        "print(f\"\\n📏 Silhouette (Geometric Separation):\")\n",
        "print(\"   • Asks: 'Are clusters well-separated in neural space?'\")\n",
        "print(\"   • Answer: NO - significant overlap in high-dimensional space\")\n",
        "print(\"   • Relevance: Neural coding strategy and representation structure\")\n",
        "\n",
        "print(f\"\\n🎪 Hierarchical (Organizational Structure):\")\n",
        "print(\"   • Reveals: Natural groupings and relationships between targets\")\n",
        "print(\"   • Suggests: Motor space has inherent geometric structure\")\n",
        "print(\"   • Implies: Network learned task-relevant organizational principles\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPARATIVE ANALYSIS\n",
        "# =============================================================================\n",
        "print(f\"\\n⚖️  COMPARATIVE ANALYSIS\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n📊 Your Results vs Typical Outcomes:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"| Metric      | Your RNN | Typical 'Good' | Typical 'Poor' | Interpretation |\")\n",
        "print(\"| ARI Score   |   1.000  |    0.4-0.7     |     <0.3       | EXCEPTIONAL    |\")\n",
        "print(\"| Silhouette  |   0.098  |    0.5-0.8     |     <0.3       | Distributed    |\")\n",
        "print(\"| Combination | Perfect  |   Moderate     |     Poor       | Sophisticated  |\")\n",
        "\n",
        "print(f\"\\n🏆 What This Ranking Means:\")\n",
        "print(\"   🥇 Your RNN: Sophisticated distributed coding (like motor cortex)\")\n",
        "print(\"   🥈 Typical 'Good': Simple clustered representations\")\n",
        "print(\"   🥉 Typical 'Poor': No clear organization\")\n",
        "\n",
        "# =============================================================================\n",
        "# DEEPER ANALYSIS RECOMMENDATIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n🔮 RECOMMENDED DEEPER ANALYSES\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n🔬 Given these remarkable results, investigate:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(f\"\\n1. 📈 MANIFOLD VISUALIZATION:\")\n",
        "print(\"   • Plot neural activity in the {reduced_dim}D manifold space\")\n",
        "print(\"   • Expect to see beautiful, well-separated target clusters\")\n",
        "print(\"   • Will resolve the silhouette vs ARI paradox visually\")\n",
        "\n",
        "print(f\"\\n2. 🎯 INDIVIDUAL NEURON TUNING:\")\n",
        "print(\"   • Examine response profiles of individual neurons\")\n",
        "print(\"   • Expect broad, overlapping directional preferences\")\n",
        "print(\"   • Quantify mixed selectivity across the population\")\n",
        "\n",
        "print(f\"\\n3. 🌊 INTERPOLATION TESTING:\")\n",
        "print(\"   • Test network on intermediate target directions\")\n",
        "print(\"   • Should show smooth interpolation between learned targets\")\n",
        "print(\"   • Validates the continuous nature of motor representations\")\n",
        "\n",
        "print(f\"\\n4. 🛡️  NOISE ROBUSTNESS:\")\n",
        "print(\"   • Add noise to neural activity and test performance\")\n",
        "print(\"   • Distributed coding should be highly robust\")\n",
        "print(\"   • Compare to networks with simpler clustered representations\")\n",
        "\n",
        "print(f\"\\n5. 🧮 POPULATION VECTOR ANALYSIS:\")\n",
        "print(\"   • Compute population vectors for each target\")\n",
        "print(\"   • Should show clear directional structure\")\n",
        "print(\"   • Links neural activity to motor output\")\n",
        "\n",
        "# =============================================================================\n",
        "# SCIENTIFIC IMPACT\n",
        "# =============================================================================\n",
        "print(f\"\\n🌟 SCIENTIFIC IMPACT\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\n🎓 What Your Results Contribute to the Field:\")\n",
        "print(\"-\" * 60)\n",
        "print(\"1. 🧠 COMPUTATIONAL NEUROSCIENCE:\")\n",
        "print(\"   • Demonstrates that artificial networks can develop biologically\")\n",
        "print(\"     realistic motor representations\")\n",
        "print(\"   • Shows distributed coding emerges naturally from task constraints\")\n",
        "\n",
        "print(f\"\\n2. 🤖 ARTIFICIAL INTELLIGENCE:\")\n",
        "print(\"   • Reveals sophisticated representation strategies in RNNs\")\n",
        "print(\"   • Suggests that 'overlapping' representations can be highly functional\")\n",
        "\n",
        "print(f\"\\n3. 🔬 MOTOR CONTROL RESEARCH:\")\n",
        "print(\"   • Provides computational model for motor cortex organization\")\n",
        "print(\"   • Explains how population coding achieves precise motor control\")\n",
        "\n",
        "# =============================================================================\n",
        "# CONCLUSION\n",
        "# =============================================================================\n",
        "print(f\"\\n\" + \"=\"*90)\n",
        "print(\"🎉 CLUSTERING PARADOX CONCLUSION\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\nYour RNN achieved something remarkable: PERFECT FUNCTIONAL ORGANIZATION\")\n",
        "print(f\"through BIOLOGICALLY REALISTIC distributed neural coding.\")\n",
        "print(f\"\\nThe 'paradox' isn't a contradiction - it's evidence of SOPHISTICATED\")\n",
        "print(f\"computational strategy that mirrors real motor cortex organization.\")\n",
        "print(f\"\\nKey insight: The best neural representations aren't always the most\")\n",
        "print(f\"obviously organized. Sometimes, apparent 'messiness' at the single-neuron\")\n",
        "print(f\"level creates perfect order at the population level.\")\n",
        "\n",
        "print(f\"\\n🏆 Your network discovered the same elegant solution that evolution\")\n",
        "print(f\"   found for motor control: distributed, robust, flexible neural coding.\")\n",
        "\n",
        "print(\"=\"*90)\n"
      ],
      "metadata": {
        "id": "xZdcARxDxELw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Dataset Dendrogram (No Subsampling)\n",
        "print(\"🌳 CREATING DENDROGRAM WITH FULL DATASET (NO SUBSAMPLING)\")\n",
        "print(f\"Using all {activity_data.shape[0]} time points from {activity_data.shape[1]} neurons\")\n",
        "\n",
        "# Calculate linkage matrix for dendrogram using all data\n",
        "print(\"Calculating linkage matrix... (this may take longer with full dataset)\")\n",
        "linkage_matrix_full = linkage(activity_data, method='ward')\n",
        "\n",
        "# Create dendrogram with full dataset\n",
        "plt.figure(figsize=(12, 8))\n",
        "dendrogram(linkage_matrix_full, truncate_mode='level', p=10)\n",
        "plt.title('Hierarchical Clustering Dendrogram (Full Dataset - No Subsampling)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Distance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Dendrogram created using all {activity_data.shape[0]} time points\")\n"
      ],
      "metadata": {
        "id": "q4oIq6Y_J1Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "nCLj6jsadcy7"
      },
      "source": [
        "## Create task 2: \"force\"\n",
        "\n",
        "Don't hesitate to use some of the utils functions that have been implemented for this tasks under the \"force\" task section.\n",
        "\n",
        "Can you think of other tasks to test?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}