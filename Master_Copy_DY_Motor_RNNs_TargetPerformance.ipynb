{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishi-patel-15/motor_rnn_target_performance/blob/Dylan's-Branch/Master_Copy_DY_Motor_RNNs_TargetPerformance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jVkqrLhdcyv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TkMBKV2Rdcyw"
      },
      "outputs": [],
      "source": [
        "# import python packages\n",
        "import os\n",
        "import numpy as np\n",
        "import sklearn.linear_model as lm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "cellView": "form",
        "id": "1npNrps5dcyy"
      },
      "outputs": [],
      "source": [
        "# @title Set the project path\n",
        "proj_path = \"proj_rnn/\"\n",
        "if not os.path.exists(proj_path):\n",
        "  os.makedirs(proj_path)\n",
        "\n",
        "# set the directories where the results will be saved\n",
        "savedir = os.path.join(proj_path, 'data/fig2/')\n",
        "if not os.path.exists(savedir):\n",
        "  os.makedirs(savedir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jZ6mtMpdcyz"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOnXNE8vdcyz"
      },
      "source": [
        "### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Bw2ScNl5dcy0"
      },
      "outputs": [],
      "source": [
        "# @title RNN encoder\n",
        "class RNN(object):\n",
        "    \"\"\"\n",
        "    Class implementing a recurrent network (not following Dale's law).\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    * N: number of neurons\n",
        "    * N_in: how many inputs can the network have\n",
        "    * N_out: how many neurons are recorded by external device\n",
        "    * g: recurrent coupling strength\n",
        "    * p: connection probability\n",
        "    * tau: neuron time constant\n",
        "    * dt: set dt for simulation\n",
        "    * delta: defines initial learning rate for FORCE\n",
        "    * P_plastic: how many neurons are plastic in the recurrent network\n",
        "    \"\"\"\n",
        "    def __init__(self, N=800, g=1.5, p=0.1, tau=0.1, dt=0.01,\n",
        "                 N_in=6):\n",
        "        # set parameters\n",
        "        self.N = N\n",
        "        self.g = g\n",
        "        self.p = p\n",
        "        self.K = int(p*N)\n",
        "        self.tau = tau\n",
        "        self.dt = dt\n",
        "\n",
        "        # create recurrent W\n",
        "        mask = np.random.rand(self.N,self.N)<self.p\n",
        "        np.fill_diagonal(mask,np.zeros(self.N))\n",
        "        self.mask = mask\n",
        "        self.W = self.g / np.sqrt(self.K) * np.random.randn(self.N,self.N) * mask\n",
        "\n",
        "        # create Win and Wout\n",
        "        self._N_in = N_in\n",
        "        self.W_in = (np.random.rand(self.N, self._N_in)-0.5)*2.\n",
        "\n",
        "    @property\n",
        "    def N_in(self):\n",
        "        return self._N_in\n",
        "\n",
        "    @N_in.setter\n",
        "    def N_in(self, value):\n",
        "        self._N_in = value\n",
        "        self.W_in = (np.random.rand(self.N, self._N_in)-0.5)*2.\n",
        "\n",
        "    def save(self,filename):\n",
        "        np.savez(\n",
        "            filename,\n",
        "            N = self.N,\n",
        "            K = self.K,\n",
        "            tau = self.tau,\n",
        "            g = self.g,\n",
        "            p = self.p,\n",
        "            dt = self.dt,\n",
        "            W_in = self.W_in,\n",
        "            W = self.W,\n",
        "            N_in = self._N_in,\n",
        "        )\n",
        "\n",
        "    def load(self,filename):\n",
        "        net = np.load(filename+'.npz')\n",
        "        self.N = int(net['N'])\n",
        "        self.dt = float(net['dt'])\n",
        "        self.K = int(net['K'])\n",
        "        self.tau = float(net['tau'])\n",
        "        self.g = float(net['g'])\n",
        "        self.p = float(net['p'])\n",
        "        self.W_in = net['W_in']\n",
        "        self.W = net['W']\n",
        "        self._N_in = int(net['N_in'])\n",
        "\n",
        "    def update_activation(self):\n",
        "        self.z = np.tanh(self.r)\n",
        "\n",
        "    def update_neurons(self,ext):\n",
        "        self.r = self.r + self.dt/self.tau * \\\n",
        "             (-self.r + np.dot(self.W, self.z) + np.dot(self.W_in,ext))\n",
        "\n",
        "        self.update_activation()\n",
        "\n",
        "    def simulate(self, T, ext=None, r0=None):\n",
        "\n",
        "        # define time\n",
        "        time = np.arange(0,T,self.dt)\n",
        "        tsteps = int(T/self.dt)\n",
        "\n",
        "        # create input in case no input is given\n",
        "        if ext is None:\n",
        "            ext = np.zeros((tsteps,self.N_in))\n",
        "\n",
        "        # check if input has the right shape\n",
        "        if ext.shape[0]!=tsteps or ext.shape[1]!=self.N_in:\n",
        "            print('ERROR: stimulus shape should be (time x number of input nodes)')\n",
        "            return\n",
        "\n",
        "        # set initial condition\n",
        "        if r0 is None:\n",
        "            self.r = (np.random.rand(self.N)-0.5)*2.\n",
        "        else:\n",
        "            self.r = r0\n",
        "        self.update_activation()\n",
        "\n",
        "        # start simulation\n",
        "        record_r = np.zeros((tsteps,self.N))\n",
        "        record_r[0,:] = self.r\n",
        "        for i in range(1,tsteps):\n",
        "            self.update_neurons(ext=ext[i])\n",
        "            # store activity\n",
        "            record_r[i,:] = self.r\n",
        "        return time, record_r, np.tanh(record_r)\n",
        "\n",
        "    def relearn(self, trials, ext, ntstart, decoder, feedback, target, delta=1.,\n",
        "                wplastic=None):\n",
        "        \"\"\"\n",
        "        Args\n",
        "          self.z: RNN network's activation\n",
        "          trials: Number of learning episodes\n",
        "          ext (np.array): stimuli (n_targets, n timesteps, n_targets?)\n",
        "          nstart: first learning index\n",
        "          decoder (np.array): (N units, 2d coordinates) decoder weights\n",
        "          feedback (np.array): (N units, 2d coordinates) feedback weights\n",
        "          target: (n_targets, N timesteps, 2d coordinates) target coordinates\n",
        "          delta: regularization parameter for the RLS learning rule.\n",
        "          wplastic: (optional) which connections are plastic (modifiable). If None then ALL modifiable.\n",
        "\n",
        "        Returns:\n",
        "\n",
        "          loss (np.array): loss by trial\n",
        "        \"\"\"\n",
        "        # get number of timesteps within trial\n",
        "        tsteps = ext.shape[1]\n",
        "\n",
        "        # set up learning\n",
        "        if wplastic is None:\n",
        "            self.W_plastic = [np.where(self.W[i,:]!=0)[0] for i in range(self.N)]   #Any non-zero recurrent connection is plastic.\n",
        "        else:\n",
        "            self.W_plastic = wplastic                                           #????\n",
        "        self.P = [1./delta*np.eye(len(self.W_plastic[i])) for i in range(len(self.W_plastic))] #Each neuron gets a P matrix, which is the inverse correlation matrix used in Recursive Least Squares (RLS) learning. It controls how the weights are updated.\n",
        "\n",
        "        # create n trials of target indices chosen from lenth of total stimuli options\n",
        "        order = np.random.choice(range(ext.shape[0]), trials, replace=True)     #Randomly picks stimuli indices to use in each trial (with replacement).\n",
        "\n",
        "        # initialize calculated loss per trial\n",
        "        record_loss = np.zeros(trials)\n",
        "\n",
        "        # loop over trials\n",
        "        for t in range(trials):\n",
        "\n",
        "            # initialize loss\n",
        "            loss = 0.\n",
        "            self.r = (np.random.rand(self.N)-0.5)*2.                            # Random initial activation\n",
        "            self.update_activation()\n",
        "\n",
        "            # loop over time\n",
        "            for i in range(1,tsteps):\n",
        "\n",
        "                # update units\n",
        "                self.update_neurons(ext=ext[order[t],i])\n",
        "\n",
        "                # learn\n",
        "                if i > ntstart and i%2==0:                                      #learning only occurs after the pulse_length/center screen time and on every second trial.\n",
        "\n",
        "                    # decode network's predicted\n",
        "                    # target coordinates\n",
        "                    c = decoder @ self.z                                        #Projects current activity (z) onto 2D space (decoder)\n",
        "\n",
        "                    # calculate prediction error between\n",
        "                    # decoded and true target coordinates (2,)\n",
        "                    errc = c - target[order[t], i]                              #Difference in predicted position (c) and actual target position at current time.\n",
        "\n",
        "                    # calculate the error update assigned to each weight\n",
        "                    err1 = feedback @ errc                                      #projected back into neuron space via feedback matrix — i.e., which neurons are responsible for this error.\n",
        "\n",
        "                    # calculate loss\n",
        "                    loss += np.mean(err1**2)\n",
        "\n",
        "                    # update plastic recurrent weights\n",
        "                    for j in range(self.N):\n",
        "                        z_plastic = self.z[self.W_plastic[j]]                   #Only update plastic synapses\n",
        "                        pz = np.dot(self.P[j], z_plastic)                       #Filtered input vector\n",
        "                        norm = (1. + np.dot(z_plastic.T,  pz))\n",
        "                        self.P[j] -= np.outer(pz, pz)/norm\n",
        "\n",
        "                        # use error-transformed feedbacks to update\n",
        "                        # plastic weights\n",
        "                        self.W[j, self.W_plastic[j]] -= err1[j] * pz / norm     #Amount of change proportional to error assigned to current neuron (j), filtered input activity (pz), and normalized by norm.\n",
        "\n",
        "            # tape loss\n",
        "            record_loss[t] = loss\n",
        "            print('Loss in Trial %d is %.5f'%(t+1,loss))\n",
        "        return record_loss\n",
        "\n",
        "    def calculate_manifold(self, trials, ext, ntstart):                         #ext = stimuli\n",
        "        tsteps = ext.shape[1]                                                   #tsteps = length of stimuli\n",
        "        T = self.dt*tsteps                                                      #T = real time\n",
        "        points = (tsteps-ntstart)\n",
        "        activity = np.zeros((points*trials,self.N))                             #store activity[timepoints,N]\n",
        "        order = np.random.choice(range(ext.shape[0]),trials,replace=True)       #chose a random trial\n",
        "        for t in range(trials):\n",
        "            time, r, z = self.simulate(T,ext[order[t]])                         #runs simulate on selected trial at all times\n",
        "            activity[t*points:(t+1)*points,:] = z[ntstart:,:]                   #stores in activity array (only after ntstart)\n",
        "        cov = np.cov(activity.T)                                                #Covariance of activity(N,trial time points)\n",
        "        ev,evec = np.linalg.eig(cov)                                            #eigenvalue and eigenvector from cov\n",
        "        pr = np.round(np.sum(ev.real)**2/np.sum(ev.real**2)).astype(int)        #Participation Ratio (PR): a measure of effective dimensionality of the manifold (See fig 3 of original paper)\n",
        "        xi = activity @ evec.real                                               #transformed activity profile into PCA space\n",
        "        return activity,cov,ev.real,evec.real,pr,xi,order\n",
        "\n",
        "def save_RNN(network, savedir:str):\n",
        "  \"\"\"write RNN object and weights in savedir\n",
        "  \"\"\"\n",
        "  network.save(savedir+'network')\n",
        "  np.save(savedir+'W_initial', network.W)\n",
        "\n",
        "def save_RNN_sinewave(network, savedir:str):\n",
        "  \"\"\"write RNN sinewave object and weights in savedir\n",
        "  \"\"\"\n",
        "  network.save(savedir + 'network_sinewave')\n",
        "  np.save(savedir + 'W_initial_sinewave', network.W)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_JwMuAhAdcy1"
      },
      "outputs": [],
      "source": [
        "# @title BCI decoders\n",
        "def train_reaching_decoder(inputP, target, order, n_output_units:int=2):        ###inputP = get manifold output[\"xi2\"][:, :, :reduced_dim #Target is get reaching targets output # Order is from manifold output as well # last is obvious idiot\n",
        "    \"\"\"train the decoder to perform the six-cue\n",
        "    motor reaching task\n",
        "    \"\"\"\n",
        "    # initialize predictor neural activity\n",
        "    X = np.zeros((inputP.shape[0]*inputP.shape[1], inputP.shape[-1]))           #X: Flattened neural data, shape = (total_timepoints, n_neurons)\n",
        "\n",
        "    # initialize predicted target\n",
        "    Y = np.zeros((inputP.shape[0]*inputP.shape[1], n_output_units))             #Y: Flattened target output, shape = (total_timepoints, n_output_units)\n",
        "\n",
        "    # fill up (This effectively flattens the trial-based data into one long array suitable for regression)\n",
        "    for j in range(inputP.shape[0]):\n",
        "        X[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = inputP[j]                #Fills in data from manifold\n",
        "        Y[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = target[order[j]]         #Fills in data from target task\n",
        "\n",
        "    # regress target against neural activity\n",
        "    reg = lm.LinearRegression()\n",
        "    reg.fit(X,Y)                                                                #Trains a linear model: Y ≈ X * coef + bias\n",
        "\n",
        "    # make predictions\n",
        "    y = reg.predict(X)\n",
        "    mse = np.mean((y-Y)**2)\n",
        "    return reg.coef_, mse                                                       #reg.coef_: The weight matrix (shape = (n_output_units, n_neurons)), representing how each neuron's activity contributes to each output dimension. mse is performance\n",
        "\n",
        "def create_reaching_task_decoder(reaching_network, n_output_units:int=2, target_max:float=0.2):\n",
        "  \"\"\"create feedforward decoder from RNN to (x,y) output units\n",
        "  for learning (random weights)\"\"\"                                              #By 'create' really just makes a matrix suitable for learning the proper weights.\n",
        "\n",
        "  # set parameters\n",
        "  SCALE = 0.04\n",
        "  DENOM = 0.2\n",
        "\n",
        "  # create random weights\n",
        "  reaching_decoder = np.random.randn(n_output_units, reaching_network.N)        #Creates a random weight matrix of shape (2, N) where N is the number of neurons.\n",
        "  initial_decoder_fac = SCALE * (target_max / DENOM)                            #Target max defined in parameters; max x,y distance of target\n",
        "\n",
        "  # normalize decoder matrix\n",
        "  reaching_decoder *= (initial_decoder_fac / np.linalg.norm(reaching_decoder))  #Scales the entire decoder matrix so that its norm matches initial_decoder_fac. Ensures that the initial decoder produces outputs of a reasonable magnitude (neither too small nor too large) — useful for stable learning.\n",
        "  return reaching_decoder                                                       #This computes the Frobenius norm (Euclidean norm for a matrix), which is: look it up, Upshot it its the magnitude of the full RNN matrix\n",
        "                                                                                #reaching_decoder *=  scalar. This scales every element in the reaching_decoder matrix by that scalar. The operation is in-place because of the *= operator, meaning it modifies the matrix directly rather than returning a new one.\n",
        "\n",
        "def train_force_exertion_decoder(inputP, target, order, n_output:int=1):        #Similar in structure to train_reaching_decoder. Unused in base data.\n",
        "    \"\"\"train the decoder to perform the force exertion\n",
        "    motor task. The network must apply force at\n",
        "    oscillating amplitude (following a sinewave function\n",
        "    of time)\n",
        "    \"\"\"\n",
        "\n",
        "    # initialize predictor neural activity\n",
        "    X = np.zeros((inputP.shape[0]*inputP.shape[1], inputP.shape[-1]))\n",
        "\n",
        "    # initialize predicted target\n",
        "    Y = np.zeros((inputP.shape[0]*inputP.shape[1], n_output))\n",
        "\n",
        "    # fill up\n",
        "    for j in range(inputP.shape[0]):\n",
        "        X[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = inputP[j]\n",
        "        Y[j*inputP.shape[1]:(j+1)*inputP.shape[1],:] = target[order[j]]\n",
        "\n",
        "    # regress target against neural activity\n",
        "    reg = lm.LinearRegression()\n",
        "    reg.fit(X, Y)\n",
        "\n",
        "    # make predictions\n",
        "    y = reg.predict(X)\n",
        "    mse = np.mean((y-Y)**2)\n",
        "    return reg.coef_, mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zRTY0RFqdcy2"
      },
      "outputs": [],
      "source": [
        "# @title Feedback weights\n",
        "def get_feedback_weights(decoder):                                              #Still not sure exactly what is going on. Isn't input essentially blank here?\n",
        "  \"\"\"calculate feedback weights from (x,y) output units back to RNN\n",
        "  as the matrix inverse of the feedforward decoder weights from the RNN to\n",
        "  the output units\"\"\"\n",
        "  return np.linalg.pinv(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oeVfbgXfdcy2"
      },
      "outputs": [],
      "source": [
        "# @title Loss function\n",
        "def get_cost(result, target, order):                                            #Part of transform_reaching. Calculates the mean squared difference between the end results and the target\n",
        "  cost = 0\n",
        "  for j in range(result.shape[0]):\n",
        "    error = result[j, :, :] - target[order[j], :, :]\n",
        "    cost += np.mean(error**2)\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B-39etsCtGMO"
      },
      "outputs": [],
      "source": [
        "# @title PLot Loss\n",
        "def plot_loss_over_trials(losses):\n",
        "    trials = len(losses)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(range(1, trials + 1), losses, marker='o', linestyle='-')\n",
        "    plt.xlabel(\"Trial\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss per Trial\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6GFzFSi6dcy3"
      },
      "outputs": [],
      "source": [
        "# @title Get the manifold\n",
        "def get_manifold(network):\n",
        "\n",
        "  # calculate the manifold\n",
        "  activity, cov, ev, evec, pr, xi, order = network.calculate_manifold(trials=manifold_trials, ext=stimulus, ntstart=pulse_length)\n",
        "\n",
        "  # reshape the activity\n",
        "  activity_reshaped = activity.reshape(manifold_trials, -1, network.N)\n",
        "  xi2 = xi.reshape(manifold_trials, -1, network.N)\n",
        "  return {\"xi2\":xi2, \"order\":order, \"xi\":xi, \"cov\":cov, \"ev\":ev, \"evec\":evec, \"pr\":pr,\"activity\":activity, \"activity_reshaped\":activity_reshaped}\n",
        "\n",
        "def save_reaching_manifold(data, T):\n",
        "  dic = {'manifold': {'original': data['manifold']}, 'perturbations': {'transformed':T}}\n",
        "  np.save(savedir + 'reaching_relearning_results', dic)\n",
        "\n",
        "def transform_reaching(reaching_network, manifold_out, W_bci4, n_output_units:int=2):\n",
        "\n",
        "  P = manifold_out[\"evec\"].real.T\n",
        "  D = np.zeros((2, reaching_network.N))\n",
        "  D[:,:reduced_dim] = W_bci4\n",
        "  transformed = D @ P\n",
        "  result = manifold_out[\"activity_reshaped\"] @ transformed.T\n",
        "  cost = get_cost(result, target[:,pulse_length:,:], manifold_out[\"order\"])\n",
        "  return transformed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def simulate_reaching(savdir, dt):\n",
        "#     import numpy as np\n",
        "#     import matplotlib.pyplot as plt\n",
        "\n",
        "#     # set plot parameters\n",
        "#     COL_ORIG = 'k'\n",
        "#     ALPHA = 1\n",
        "\n",
        "#     # load data\n",
        "#     data = np.load(savdir + 'reaching_experiment_results.npy', allow_pickle=True).item()\n",
        "#     activity = data['manifold']['activity2']  # corrected key\n",
        "\n",
        "#     # Load weights (assume they are under decoding)\n",
        "#     weights = data['decoding']['weights']\n",
        "#     o_original = activity @ weights.T  # corrected projection\n",
        "\n",
        "#     # reconstruct trajectories from velocities\n",
        "#     pos_original = np.zeros(o_original.shape)\n",
        "#     for j in range(1, activity.shape[1]):  # start at 1 to use j-1 safely\n",
        "#         pos_original[:, j, :] = pos_original[:, j-1, :] + o_original[:, j, :] * dt\n",
        "\n",
        "#     start_points = pos_original[:, 0, :]  # shape (trials x 2)\n",
        "\n",
        "#     # Get targets\n",
        "#     target_traj = data['target']  # shape (n_targets, tsteps, 2)\n",
        "#     target_positions = target_traj[:, -1, :]  # final position for each target\n",
        "\n",
        "#     # Number of trials\n",
        "#     manifold_trials = data['params']['manifold_trials']\n",
        "\n",
        "#     # Plot trajectories\n",
        "#     plt.figure(figsize=(15, 10), dpi=96)\n",
        "#     plt.subplot(2, 3, 3)\n",
        "\n",
        "#     for j in range(manifold_trials):\n",
        "#         plt.plot(pos_original[j, :, 0], pos_original[j, :, 1], COL_ORIG, alpha=ALPHA)\n",
        "\n",
        "#     # Plot dashed lines from start to target\n",
        "#     for j in range(manifold_trials):\n",
        "#         target_idx = j % target_positions.shape[0]\n",
        "#         plt.plot([start_points[j, 0], target_positions[target_idx, 0]],\n",
        "#                  [start_points[j, 1], target_positions[target_idx, 1]],\n",
        "#                  'r--', alpha=0.5)\n",
        "\n",
        "#     # Plot all target positions as red circles\n",
        "#     for tx, ty in target_positions:\n",
        "#         plt.plot(tx, ty, 'ro', markersize=10)\n",
        "\n",
        "#     plt.title('simulated reaching')\n",
        "#     plt.xlabel('x-position on screen')\n",
        "#     plt.ylabel('y-position on screen')\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "id": "3iW97HMIVsqO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev5EBlU4dcy4"
      },
      "source": [
        "### Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zrb4ZucRdcy4"
      },
      "outputs": [],
      "source": [
        "# @title \"reaching\" task\n",
        "def create_reaching_task_stimuli(tsteps:int, pulse_steps:int, n_targets:int=6, amplitude:float=1., twod:bool=False):\n",
        "    \"\"\"create the set of stimuli, which we sample from at each trial\n",
        "\n",
        "    Args:\n",
        "      tsteps (int):\n",
        "      pulse_steps (int):\n",
        "      n_targets (int):\n",
        "      amplitude (float):\n",
        "      twod (bool):\n",
        "\n",
        "    Returns:\n",
        "      (np.array): array of (n_targets, pulse_steps, n_targets) stimuli\n",
        "    \"\"\"\n",
        "\n",
        "    # create stimulus\n",
        "    stimulus = np.zeros((n_targets, tsteps, n_targets))\n",
        "    if twod:\n",
        "        phis = np.linspace(0,2*np.pi,targets,endpoint=False)\n",
        "        for j in range(stimulus.shape[0]):\n",
        "            stimulus[j,:pulse_length,0] = amplitude*np.cos(phis[j])\n",
        "            stimulus[j,:pulse_length,1] = amplitude*np.sin(phis[j])\n",
        "            stimulus[j,:pulse_length,2:] = 0\n",
        "    else:\n",
        "        for j in range(n_targets):\n",
        "            stimulus[j,:pulse_steps,j] = amplitude\n",
        "    return stimulus\n",
        "\n",
        "# def create_reaching_task_targets(tsteps, pulse_steps, n_targets:int=6, stype='constant', target_max:float=0.2):\n",
        "#     \"\"\"create the set of target coordinates (6 by default) that the network\n",
        "#     must reach before the end of a trial. The network starts from the center of\n",
        "#     the computer screen (coordinate: (0,0))\n",
        "#     \"\"\"\n",
        "#     # create target trajectories\n",
        "#     phis = np.linspace(0, 2*np.pi, n_targets, endpoint=False)\n",
        "#     rs = np.zeros(tsteps)\n",
        "\n",
        "#     # define each target's x and y coordinate\n",
        "#     rs[pulse_steps:] = np.ones(tsteps-pulse_steps)*target_max                   #Stimuli start at 0,0 then move to final position at 'pulse_steps'\n",
        "#     traj = np.zeros((n_targets,tsteps,2))\n",
        "#     for j in range(n_targets):\n",
        "\n",
        "#         # create x-coordinate on screen\n",
        "#         traj[j,:,0] = rs*np.cos(phis[j])\n",
        "\n",
        "#         # create y-coordinate on screen\n",
        "#         traj[j,:,1] = rs*np.sin(phis[j])\n",
        "#     return traj\n",
        "\n",
        "def create_reaching_task_targets(tsteps, pulse_steps, n_targets:int=6, stype='constant', target_max:float=0.2):\n",
        "    \"\"\"\n",
        "    Create the set of target coordinates (6 by default) that the network\n",
        "    must reach before the end of a trial. The network starts from the center of\n",
        "    the screen (coordinate: (0,0)).\n",
        "\n",
        "    Parameters:\n",
        "        tsteps (int): total number of time steps per trial\n",
        "        pulse_steps (int): time step at which stimulus starts (before which target = 0)\n",
        "        n_targets (int): number of different targets\n",
        "        stype (str): 'constant' for evenly spaced targets, 'random' for random target directions\n",
        "        target_max (float): max radius of target position (e.g., 0.2)\n",
        "\n",
        "    Returns:\n",
        "        traj (ndarray): shape (n_targets, tsteps, 2), target trajectories\n",
        "    \"\"\"\n",
        "    if stype == 'constant':\n",
        "        phis = np.linspace(0, 2 * np.pi, n_targets, endpoint=False)\n",
        "    elif stype == 'random':\n",
        "        phis = np.random.uniform(0, 2 * np.pi, size=n_targets)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized stype '{stype}'. Use 'constant' or 'random'.\")\n",
        "\n",
        "    rs = np.zeros(tsteps)\n",
        "    rs[pulse_steps:] = target_max  # Targets are at origin until pulse, then jump to outer radius\n",
        "\n",
        "    traj = np.zeros((n_targets, tsteps, 2))\n",
        "    for j in range(n_targets):\n",
        "        traj[j, :, 0] = rs * np.cos(phis[j])\n",
        "        traj[j, :, 1] = rs * np.sin(phis[j])\n",
        "\n",
        "    return traj\n",
        "\n",
        "def plot_reaching_task_stimuli(stimulus, n_targets:int, tsteps:int, T:int):\n",
        "\n",
        "  # plot target cue with \"pulse_steps\" duration\n",
        "  # at the beginning of each trial\n",
        "  stimulus_set = np.arange(0, n_targets,1)\n",
        "\n",
        "  fig, axes = plt.subplots(n_targets, 1, figsize=(30,9))\n",
        "\n",
        "  for target in stimulus_set:\n",
        "    axes[target].imshow(stimulus[target,:,:].T, aspect=10, cmap=\"binary\");\n",
        "\n",
        "    # legend\n",
        "    axes[target].set_yticks(stimulus_set)\n",
        "    axes[target].set_yticklabels(stimulus_set, fontsize=9)\n",
        "    axes[target].set_xticks([0, tsteps])\n",
        "    axes[target].set_xticklabels([0, T])\n",
        "    axes[target].set_ylabel(\"possible targets\", fontsize=9)\n",
        "\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "\n",
        "  fig.tight_layout()\n",
        "\n",
        "  print(\"stimuli:\")\n",
        "  print(f\"-a set of {stimulus.shape[0]} possible trial stimuli (panels)\")\n",
        "  print(f\"-{stimulus.shape[1]} timesteps within a trial stimulus\")\n",
        "  print(f\"-{stimulus.shape[2]} possible cued target in a trial stimulus\")\n",
        "\n",
        "def plot_reaching_task_targets(target, tsteps:int, T:int):\n",
        "\n",
        "  # count targets\n",
        "  n_targets = target.shape[0]\n",
        "\n",
        "  # plot target coordinates throughout trial\n",
        "  fig, axes = plt.subplots(n_targets,1, figsize=(6,6))\n",
        "  for target_i in tuple(range(n_targets)):\n",
        "    axes[target_i].plot(target[target_i,:,:])\n",
        "\n",
        "    # legend\n",
        "    axes[target_i].set_xticks([0, tsteps])\n",
        "    axes[target_i].set_xticklabels([0, T])\n",
        "    axes[target_i].set_ylabel(\"target\" \"\\n\" \"coord (a.u.)\", fontsize=9)\n",
        "    axes[target_i].set_ylim([target.min()-0.01, target.max()+0.01])\n",
        "    # axes[target_i].legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False)\n",
        "\n",
        "\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "  plt.legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False)\n",
        "\n",
        "  fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "cellView": "form",
        "id": "TTLiJW6Xdcy4"
      },
      "outputs": [],
      "source": [
        "# @title \"force\" task\n",
        "def create_force_task_stimuli(tsteps:int, pulse_steps:int, n_targets:int=1, amplitude:float=1., twod:bool=False):\n",
        "    \"\"\"create a stimulus set\n",
        "\n",
        "    Args:\n",
        "      tsteps (int):\n",
        "      pulse_steps (int):\n",
        "      n_targets (int):\n",
        "      amplitude (float)\n",
        "      twod (bool):\n",
        "\n",
        "    Returns:\n",
        "      (np.array): array of (n_targets, pulse_steps, n_targets) stimuli\n",
        "    \"\"\"\n",
        "\n",
        "    # create stimuli\n",
        "    stimulus = np.zeros((n_targets, tsteps, n_targets))\n",
        "    for j in range(n_targets):\n",
        "        stimulus[j,:pulse_steps,j] = amplitude\n",
        "    return stimulus\n",
        "\n",
        "def plot_force_stimuli(stimulus, n_targets:int, tsteps:int, T:int):\n",
        "\n",
        "  # plot target cue with \"pulse_steps\" duration\n",
        "  # at the beginning of each trial\n",
        "  stimulus_set = np.arange(0, n_targets, 1)\n",
        "  fig, axes = plt.subplots(n_targets, 1, figsize=(30,9))\n",
        "  for target in stimulus_set:\n",
        "\n",
        "    # plot\n",
        "    axes[target].imshow(stimulus[target,:,:].T, aspect=10, cmap=\"binary\");\n",
        "\n",
        "    # legend\n",
        "    axes[target].set_yticks(stimulus_set)\n",
        "    axes[target].set_yticklabels(stimulus_set, fontsize=9)\n",
        "    axes[target].set_xticks([0, tsteps])\n",
        "    axes[target].set_xticklabels([0, T])\n",
        "    axes[target].set_ylabel(\"possible targets\", fontsize=9)\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\")\n",
        "  fig.tight_layout()\n",
        "  print(\"stimuli:\")\n",
        "  print(f\"-a set of {stimulus.shape[0]} possible trial stimuli (panels)\")\n",
        "  print(f\"-{stimulus.shape[1]} timesteps within a trial stimulus\")\n",
        "  print(f\"-{stimulus.shape[2]} possible cued target in a trial stimulus\")\n",
        "\n",
        "def create_force_task_targets(tsteps, pulse_steps, targets:list=[1, 10], target_max:float=0.2):\n",
        "  \"\"\"exert force with an oscillatorily increasing and decreasing amplitude\n",
        "  \"\"\"\n",
        "  n_targets = len(targets)\n",
        "  rs = np.zeros(tsteps)\n",
        "  traj = np.zeros((n_targets, tsteps, 1))\n",
        "  rs[pulse_steps:] = np.ones(tsteps - pulse_steps) * target_max\n",
        "  x_coord = np.linspace(-2*np.pi, 2*np.pi, tsteps, endpoint=False)\n",
        "  freq = []\n",
        "  for ix in range(n_targets):\n",
        "    traj[ix,:,0] = rs * np.sin(targets[ix] * x_coord)\n",
        "  return traj\n",
        "\n",
        "def plot_force_task_targets(target, tsteps:int, T:int):\n",
        "\n",
        "  # count targets\n",
        "  n_targets = target.shape[0]\n",
        "\n",
        "  # plot target coordinates throughout trial\n",
        "  fig, axes = plt.subplots(n_targets,1, figsize=(6,6));\n",
        "  for target_i in tuple(range(n_targets)):\n",
        "\n",
        "    # plot\n",
        "    axes[target_i].plot(target[target_i,:,:]);\n",
        "\n",
        "    # legend\n",
        "    axes[target_i].set_xticks([0, tsteps]);\n",
        "    axes[target_i].set_xticklabels([0, T]);\n",
        "    axes[target_i].set_ylabel(\"target\" \"\\n\" \"coord (a.u.)\", fontsize=9);\n",
        "    axes[target_i].set_ylim([target.min()-0.01, target.max()+0.01]);\n",
        "  axes[-1].set_xlabel(\"time within a trial (secs)\");\n",
        "  plt.legend([\"x-coord\", \"y-coord\"], fontsize=9, frameon=False);\n",
        "  fig.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcQfmmJldcy5"
      },
      "source": [
        "## Create task 1: \"reaching\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WltOVBJ5dcy5"
      },
      "outputs": [],
      "source": [
        "# @title set parameters\n",
        "# TODO: create dictionary\n",
        "\n",
        "seed_id = 2                 # random seed for this simulation\n",
        "np.random.seed(seed_id)\n",
        "\n",
        "# time parameters\n",
        "dt = 0.01                   # time discretization (secs, see paper table 1)\n",
        "T = 2                       # trial duration (secs, see paper table 1)\n",
        "time = np.arange(0, T, dt)\n",
        "tsteps = len(time)          # number of time steps within a trial\n",
        "pulse_length = int(0.2/dt)  # pulse length in number of timesteps\n",
        "\n",
        "# network parameters\n",
        "N = 800                     # RNN number of units\n",
        "g = 1.5                     # RNN recurrent connection strengths (a.u)\n",
        "p = 0.1                     # RNN connection probability\n",
        "tau = 0.1                   # unit time constant tau (secs)\n",
        "N_OUTPUT_UNITS = 2          # number of output units (2 for x and y)\n",
        "\n",
        "# task parameters\n",
        "targets = 6                 # number of reaching targets\n",
        "stimulus_type = 'constant'  # constant, random (linear, normal)\n",
        "target_max = 0.2            # 0.2 or 0.01\n",
        "n_learning1_trials = 20       # initial network learning\n",
        "delta = 20.\n",
        "relearning_trials = 80     # relearning\n",
        "deltarec = 20.\n",
        "\n",
        "# analyses parameters\n",
        "manifold_trials = 50        # manifold calculation\n",
        "reduced_dim = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BqbMmmSdcy5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Create stimuli and targets\n",
        "\n",
        "# create stimuli and plot\n",
        "stimulus = create_reaching_task_stimuli(tsteps, pulse_length, n_targets=targets, twod=False)\n",
        "plot_reaching_task_stimuli(stimulus, targets, tsteps, T)\n",
        "\n",
        "# create target (targets x timesteps x 2D coordinates) and plot\n",
        "target = create_reaching_task_targets(\n",
        "    tsteps,\n",
        "    pulse_length,\n",
        "    n_targets=targets,\n",
        "    stype=stimulus_type,\n",
        "    target_max=target_max\n",
        "    )\n",
        "plot_reaching_task_targets(target, tsteps, T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "574307IZdcy6"
      },
      "outputs": [],
      "source": [
        "# @title build and train the network\n",
        "# create and save RNN encoder\n",
        "reaching_network = RNN(N=N, g=g, p=p, tau=tau, dt=dt, N_in=targets)\n",
        "save_RNN(reaching_network, savedir)\n",
        "\n",
        "# create feedforward decoder from RNN to (x,y) output units\n",
        "reaching_decoder = create_reaching_task_decoder(reaching_network,\n",
        "                                                n_output_units=N_OUTPUT_UNITS)\n",
        "\n",
        "# create feedback weights from (x,y) output units back to RNN\n",
        "reaching_feedback = get_feedback_weights(reaching_decoder)\n",
        "\n",
        "# train and save the RNN encoder weights (learn the task)\n",
        "reaching_loss = reaching_network.relearn(n_learning1_trials, stimulus,\n",
        "                                         pulse_length, reaching_decoder,\n",
        "                                         reaching_feedback, target, delta=delta, wplastic = None)\n",
        "plot_loss_over_trials(reaching_loss)\n",
        "np.save(f'{savedir}W_stabilized_reaching', reaching_network.W)\n",
        "w1_reaching = reaching_network.W.copy()\n",
        "\n",
        "# get the RNN's manifold\n",
        "manifold_out = get_manifold(reaching_network)\n",
        "\n",
        "# train the decoder\n",
        "W_bci4, l4 = train_reaching_decoder(manifold_out[\"xi2\"][:, :, :reduced_dim],\n",
        "                                    target[:, pulse_length:, :],\n",
        "                                    manifold_out[\"order\"],\n",
        "                                    n_output_units=N_OUTPUT_UNITS)\n",
        "\n",
        "# transform\n",
        "transformed = transform_reaching(reaching_network, manifold_out,\n",
        "                                 W_bci4, n_output_units=N_OUTPUT_UNITS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHhq6r3Vdcy7"
      },
      "outputs": [],
      "source": [
        "# @title Save run data\n",
        "# format and save data for this run\n",
        "run_data = {\n",
        "    'params':{\n",
        "        'dt':dt,\n",
        "        'T':T,\n",
        "        'time':time,\n",
        "        'tsteps':tsteps,\n",
        "        'pulse_length':pulse_length,\n",
        "        'manifold_trials':manifold_trials,\n",
        "        'target_max':target_max,\n",
        "        'stimulus_type':stimulus_type,\n",
        "        'N':N,\n",
        "        'tau':tau,\n",
        "        'g':g,\n",
        "        'p':p\n",
        "        },\n",
        "    'stimulus':stimulus,\n",
        "    'target':target,\n",
        "    'stabilizing':{\n",
        "        'learning_trials':n_learning1_trials,\n",
        "        'delta':delta,\n",
        "        'decoder':reaching_decoder,\n",
        "        'feedback':reaching_feedback,\n",
        "        'stabilize_loss':reaching_loss\n",
        "        },\n",
        "    'manifold':{\n",
        "        'activity':manifold_out[\"activity\"],\n",
        "        'activity2':manifold_out[\"activity_reshaped\"],\n",
        "        'xi':manifold_out[\"xi\"],\n",
        "        'xi2':manifold_out[\"xi2\"],\n",
        "        'cov':manifold_out[\"cov\"],\n",
        "        'ev':manifold_out[\"ev\"],\n",
        "        'evec':manifold_out[\"evec\"],\n",
        "        'pr':manifold_out[\"pr\"],\n",
        "        'order': manifold_out[\"order\"]\n",
        "        },\n",
        "    'decoding':{\n",
        "        'reduced_dim': reduced_dim,\n",
        "        'weights': W_bci4,\n",
        "        'loss':l4\n",
        "        }\n",
        "        }\n",
        "np.save(f'{savedir}reaching_experiment_results', run_data)\n",
        "\n",
        "# save manifold data separately\n",
        "save_reaching_manifold(run_data, transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nenZCf61dcy3"
      },
      "outputs": [],
      "source": [
        "# @title simulate_reaching\n",
        "def simulate_reaching(savdir, dt):\n",
        "\n",
        "  # set plot parameters\n",
        "  COL_ORIG = 'k'\n",
        "  ALPHA = 1\n",
        "\n",
        "  # Load velocity (manifold) data from relearning run\n",
        "  data = np.load(savdir + 'reaching_relearning_results.npy', allow_pickle=True).item()\n",
        "\n",
        "  # Load full experimental data (with targets)\n",
        "  data_target = np.load(savdir + 'reaching_experiment_results.npy', allow_pickle=True).item()\n",
        "\n",
        "  # Extract activity and projection weights\n",
        "  activity = data['manifold']['original']['activity2']              # shape: (trials * timesteps, N)\n",
        "  # o_original = activity @ data['perturbations']['transformed'].T\n",
        "  weights = data['perturbations']['transformed']        # shape: (2, N)\n",
        "  o_original = activity @ weights.T                     # shape: (trials * timesteps, 2)\n",
        "\n",
        "  # Reshape for plotting\n",
        "  manifold_trials = data_target['params']['manifold_trials']\n",
        "  tsteps = data_target['params']['tsteps']\n",
        "  # pos_original = np.zeros((manifold_trials, tsteps, 2))\n",
        "  # activity_reshaped = o_original.reshape(manifold_trials, tsteps, 2)\n",
        "\n",
        "  # reconstruct trajectories from velocities\n",
        "  pos_original = np.zeros(o_original.shape)\n",
        "  for j in range(1, activity.shape[1]):  # start at 1 to use j-1 safely\n",
        "    pos_original[:, j, :] = pos_original[:, j-1, :] + o_original[:, j, :] * dt\n",
        "\n",
        "  start_points = pos_original[:, 0, :]  # shape (trials x 2)\n",
        "\n",
        "  # Get targets\n",
        "  target_traj = data_target['target']  # shape (n_targets, tsteps, 2)\n",
        "  target_positions = target_traj[:, -1, :]  # final position for each target\n",
        "\n",
        "  # Plot trajectories\n",
        "  plt.figure(figsize=(15, 10), dpi=96)\n",
        "  plt.subplot(2, 3, 3)\n",
        "\n",
        "  for j in range(manifold_trials):\n",
        "    plt.plot(pos_original[j, :, 0], pos_original[j, :, 1], COL_ORIG, alpha=ALPHA)\n",
        "\n",
        "  # Plot dashed lines from start to target\n",
        "  for j in range(manifold_trials):\n",
        "    target_idx = j % target_positions.shape[0]\n",
        "    plt.plot([start_points[j, 0], target_positions[target_idx, 0]],\n",
        "             [start_points[j, 1], target_positions[target_idx, 1]],\n",
        "             'r--', alpha=0.5)\n",
        "\n",
        "  # Plot all target positions as red circles\n",
        "  for tx, ty in target_positions:\n",
        "    plt.plot(tx, ty, 'ro', markersize=10)\n",
        "\n",
        "  plt.title('simulated reaching')\n",
        "  plt.xlabel('x-position on screen')\n",
        "  plt.ylabel('y-position on screen')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pW48mvdcy7"
      },
      "source": [
        "### Simulate Reaching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wvh6d-XDdcy7"
      },
      "outputs": [],
      "source": [
        "# @title Model Reaching Performance\n",
        "trajectories = simulate_reaching(savedir, dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCLj6jsadcy7"
      },
      "source": [
        "## Create task 2: \"force\"\n",
        "\n",
        "Don't hesitate to use some of the utils functions that have been implemented for this tasks under the \"force\" task section.\n",
        "\n",
        "Can you think of other tasks to test?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}